{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c5104a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keras\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, BatchNormalization,Input\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "import keras.backend as Kr\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "from numpy import exp\n",
    "# Library for Gaussian process\n",
    "# import GPy\n",
    "##Library for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "import matplotlib;matplotlib.rcParams['figure.figsize'] = (10,7)\n",
    "import pylab \n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e5195a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>proj_var1</th>\n",
       "      <th>proj_var2</th>\n",
       "      <th>threshold</th>\n",
       "      <th>dist_frm_orig</th>\n",
       "      <th>threshold2</th>\n",
       "      <th>constant</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.898876</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.916991</td>\n",
       "      <td>-4.270493</td>\n",
       "      <td>-2.842809</td>\n",
       "      <td>-4.380952</td>\n",
       "      <td>1</td>\n",
       "      <td>11.726556</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.910112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.123750</td>\n",
       "      <td>-4.581233</td>\n",
       "      <td>-3.129122</td>\n",
       "      <td>-4.573235</td>\n",
       "      <td>1</td>\n",
       "      <td>14.207576</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.921348</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.942157</td>\n",
       "      <td>-4.591575</td>\n",
       "      <td>-3.008760</td>\n",
       "      <td>-4.492402</td>\n",
       "      <td>1</td>\n",
       "      <td>13.135607</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.932584</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.018496</td>\n",
       "      <td>-4.650880</td>\n",
       "      <td>-3.088819</td>\n",
       "      <td>-4.546168</td>\n",
       "      <td>1</td>\n",
       "      <td>13.843947</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-3.403380</td>\n",
       "      <td>-4.727132</td>\n",
       "      <td>-3.389361</td>\n",
       "      <td>-4.748008</td>\n",
       "      <td>1</td>\n",
       "      <td>16.669045</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x    y      var1      var2  proj_var1  proj_var2  threshold  \\\n",
       "0  0.898876  0.0 -2.916991 -4.270493  -2.842809  -4.380952          1   \n",
       "1  0.910112  0.0 -3.123750 -4.581233  -3.129122  -4.573235          1   \n",
       "2  0.921348  0.0 -2.942157 -4.591575  -3.008760  -4.492402          1   \n",
       "3  0.932584  0.0 -3.018496 -4.650880  -3.088819  -4.546168          1   \n",
       "4  0.943820  0.0 -3.403380 -4.727132  -3.389361  -4.748008          1   \n",
       "\n",
       "   dist_frm_orig  threshold2  constant  class  \n",
       "0      11.726556           3         0      3  \n",
       "1      14.207576           3         0      3  \n",
       "2      13.135607           3         0      3  \n",
       "3      13.843947           3         0      3  \n",
       "4      16.669045           4         0      4  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_loc = pd.read_csv(\"2D_biv_matern_8100_projection.csv\", sep = \",\")\n",
    "df_loc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e86076",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train,df_test = train_test_split(df_loc, test_size = 0.06)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca1c818",
   "metadata": {},
   "source": [
    "## Projected data classification \n",
    "\n",
    "### 140 classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a316c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_list_var1 = list()\n",
    "# df_train1 = df_train\n",
    "# print(df_train1.head(1))\n",
    "# df_loc[\"threshold_var1\"] = df_loc[\"threshold_var1\"] - 1\n",
    "# dummy_y = np_utils.to_categorical(df_loc[\"threshold_var1\"])\n",
    "# n = dummy_y.shape[1]\n",
    "# print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec90738d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "140"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(df_train[\"class\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "022a16b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n",
      "7614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning:Pass classes=[  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 140], y=3940     64\n",
      "4096     69\n",
      "5024     81\n",
      "6186    103\n",
      "1453     25\n",
      "       ... \n",
      "1828     28\n",
      "4277     65\n",
      "3624     64\n",
      "7979    127\n",
      "47        4\n",
      "Name: class, Length: 7614, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model for variable 1.\n",
      "Train on 6852 samples, validate on 762 samples\n",
      "Epoch 1/500\n",
      " - 1s - loss: 4.9204 - accuracy: 0.0105 - val_loss: 5.1263 - val_accuracy: 0.0039\n",
      "Epoch 2/500\n",
      " - 0s - loss: 4.8615 - accuracy: 0.0149 - val_loss: 5.1100 - val_accuracy: 0.0066\n",
      "Epoch 3/500\n",
      " - 0s - loss: 4.4704 - accuracy: 0.0344 - val_loss: 4.8218 - val_accuracy: 0.0394\n",
      "Epoch 4/500\n",
      " - 0s - loss: 4.0224 - accuracy: 0.0660 - val_loss: 4.5767 - val_accuracy: 0.0564\n",
      "Epoch 5/500\n",
      " - 0s - loss: 3.6450 - accuracy: 0.0997 - val_loss: 4.5958 - val_accuracy: 0.0997\n",
      "Epoch 6/500\n",
      " - 0s - loss: 3.3678 - accuracy: 0.1299 - val_loss: 4.9377 - val_accuracy: 0.0906\n",
      "Epoch 7/500\n",
      " - 0s - loss: 3.1837 - accuracy: 0.1421 - val_loss: 5.1902 - val_accuracy: 0.1115\n",
      "Epoch 8/500\n",
      " - 0s - loss: 3.0346 - accuracy: 0.1547 - val_loss: 5.1803 - val_accuracy: 0.1588\n",
      "Epoch 9/500\n",
      " - 1s - loss: 2.8897 - accuracy: 0.1823 - val_loss: 5.2126 - val_accuracy: 0.1732\n",
      "Epoch 10/500\n",
      " - 0s - loss: 2.7702 - accuracy: 0.1839 - val_loss: 5.7238 - val_accuracy: 0.1640\n",
      "Epoch 11/500\n",
      " - 1s - loss: 2.7212 - accuracy: 0.1961 - val_loss: 5.7690 - val_accuracy: 0.1654\n",
      "Epoch 12/500\n",
      " - 1s - loss: 2.6180 - accuracy: 0.2099 - val_loss: 5.8964 - val_accuracy: 0.1916\n",
      "Epoch 13/500\n",
      " - 1s - loss: 2.5556 - accuracy: 0.2182 - val_loss: 6.5325 - val_accuracy: 0.1903\n",
      "Epoch 14/500\n",
      " - 1s - loss: 2.5007 - accuracy: 0.2280 - val_loss: 6.3356 - val_accuracy: 0.1982\n",
      "Epoch 15/500\n",
      " - 0s - loss: 2.4629 - accuracy: 0.2277 - val_loss: 6.1891 - val_accuracy: 0.2257\n",
      "Epoch 16/500\n",
      " - 0s - loss: 2.4103 - accuracy: 0.2379 - val_loss: 6.5203 - val_accuracy: 0.2244\n",
      "Epoch 17/500\n",
      " - 0s - loss: 2.3838 - accuracy: 0.2465 - val_loss: 6.6516 - val_accuracy: 0.2388\n",
      "Epoch 18/500\n",
      " - 0s - loss: 2.3897 - accuracy: 0.2364 - val_loss: 6.5602 - val_accuracy: 0.2047\n",
      "Epoch 19/500\n",
      " - 1s - loss: 2.3688 - accuracy: 0.2354 - val_loss: 6.7130 - val_accuracy: 0.2415\n",
      "Epoch 20/500\n",
      " - 0s - loss: 2.2565 - accuracy: 0.2553 - val_loss: 6.8369 - val_accuracy: 0.2454\n",
      "Epoch 21/500\n",
      " - 0s - loss: 2.2874 - accuracy: 0.2623 - val_loss: 6.6569 - val_accuracy: 0.2297\n",
      "Epoch 22/500\n",
      " - 0s - loss: 2.2099 - accuracy: 0.2776 - val_loss: 6.9283 - val_accuracy: 0.2336\n",
      "Epoch 23/500\n",
      " - 0s - loss: 2.1998 - accuracy: 0.2704 - val_loss: 6.7539 - val_accuracy: 0.2336\n",
      "Epoch 24/500\n",
      " - 1s - loss: 2.1675 - accuracy: 0.2713 - val_loss: 7.0665 - val_accuracy: 0.2598\n",
      "Epoch 25/500\n",
      " - 1s - loss: 2.1524 - accuracy: 0.2855 - val_loss: 7.1332 - val_accuracy: 0.2454\n",
      "Epoch 26/500\n",
      " - 0s - loss: 2.1247 - accuracy: 0.2866 - val_loss: 6.7979 - val_accuracy: 0.2480\n",
      "Epoch 27/500\n",
      " - 0s - loss: 2.1277 - accuracy: 0.2849 - val_loss: 6.7208 - val_accuracy: 0.2454\n",
      "Epoch 28/500\n",
      " - 0s - loss: 2.0838 - accuracy: 0.2917 - val_loss: 6.8807 - val_accuracy: 0.2388\n",
      "Epoch 29/500\n",
      " - 0s - loss: 2.1050 - accuracy: 0.2933 - val_loss: 6.8431 - val_accuracy: 0.2323\n",
      "Epoch 30/500\n",
      " - 1s - loss: 2.0610 - accuracy: 0.2958 - val_loss: 7.4444 - val_accuracy: 0.2572\n",
      "Epoch 31/500\n",
      " - 1s - loss: 2.0535 - accuracy: 0.2987 - val_loss: 6.9821 - val_accuracy: 0.2533\n",
      "Epoch 32/500\n",
      " - 1s - loss: 2.0110 - accuracy: 0.3041 - val_loss: 7.4702 - val_accuracy: 0.2454\n",
      "Epoch 33/500\n",
      " - 0s - loss: 2.0427 - accuracy: 0.3009 - val_loss: 7.2121 - val_accuracy: 0.2677\n",
      "Epoch 34/500\n",
      " - 0s - loss: 1.9878 - accuracy: 0.3088 - val_loss: 7.1484 - val_accuracy: 0.2927\n",
      "Epoch 35/500\n",
      " - 0s - loss: 1.9543 - accuracy: 0.3193 - val_loss: 6.9741 - val_accuracy: 0.2664\n",
      "Epoch 36/500\n",
      " - 0s - loss: 1.9777 - accuracy: 0.3135 - val_loss: 7.2549 - val_accuracy: 0.2913\n",
      "Epoch 37/500\n",
      " - 1s - loss: 1.9323 - accuracy: 0.3176 - val_loss: 7.3243 - val_accuracy: 0.3018\n",
      "Epoch 38/500\n",
      " - 0s - loss: 1.9449 - accuracy: 0.3253 - val_loss: 7.2244 - val_accuracy: 0.2507\n",
      "Epoch 39/500\n",
      " - 1s - loss: 1.9104 - accuracy: 0.3279 - val_loss: 7.5507 - val_accuracy: 0.2756\n",
      "Epoch 40/500\n",
      " - 1s - loss: 1.8940 - accuracy: 0.3365 - val_loss: 7.2732 - val_accuracy: 0.2822\n",
      "Epoch 41/500\n",
      " - 1s - loss: 1.8900 - accuracy: 0.3368 - val_loss: 7.7786 - val_accuracy: 0.2625\n",
      "Epoch 42/500\n",
      " - 1s - loss: 1.9510 - accuracy: 0.3272 - val_loss: 7.1648 - val_accuracy: 0.2756\n",
      "Epoch 43/500\n",
      " - 1s - loss: 1.8645 - accuracy: 0.3256 - val_loss: 7.0674 - val_accuracy: 0.2848\n",
      "Epoch 44/500\n",
      " - 0s - loss: 1.8660 - accuracy: 0.3424 - val_loss: 7.1596 - val_accuracy: 0.2874\n",
      "Epoch 45/500\n",
      " - 0s - loss: 1.8732 - accuracy: 0.3330 - val_loss: 7.1653 - val_accuracy: 0.2822\n",
      "Epoch 46/500\n",
      " - 0s - loss: 1.8385 - accuracy: 0.3479 - val_loss: 7.5614 - val_accuracy: 0.2743\n",
      "Epoch 47/500\n",
      " - 1s - loss: 1.8509 - accuracy: 0.3450 - val_loss: 7.0775 - val_accuracy: 0.2835\n",
      "Epoch 48/500\n",
      " - 0s - loss: 1.8506 - accuracy: 0.3365 - val_loss: 7.3302 - val_accuracy: 0.3281\n",
      "Epoch 49/500\n",
      " - 1s - loss: 1.8031 - accuracy: 0.3437 - val_loss: 7.3289 - val_accuracy: 0.2822\n",
      "Epoch 50/500\n",
      " - 0s - loss: 1.8438 - accuracy: 0.3468 - val_loss: 7.2147 - val_accuracy: 0.2900\n",
      "Epoch 51/500\n",
      " - 0s - loss: 1.8368 - accuracy: 0.3510 - val_loss: 7.2939 - val_accuracy: 0.2782\n",
      "Epoch 52/500\n",
      " - 0s - loss: 1.8083 - accuracy: 0.3592 - val_loss: 7.1161 - val_accuracy: 0.3202\n",
      "Epoch 53/500\n",
      " - 0s - loss: 1.7979 - accuracy: 0.3529 - val_loss: 7.4076 - val_accuracy: 0.3097\n",
      "Epoch 54/500\n",
      " - 0s - loss: 1.7544 - accuracy: 0.3650 - val_loss: 7.4004 - val_accuracy: 0.3097\n",
      "Epoch 55/500\n",
      " - 1s - loss: 1.8113 - accuracy: 0.3530 - val_loss: 7.5702 - val_accuracy: 0.2992\n",
      "Epoch 56/500\n",
      " - 1s - loss: 1.7399 - accuracy: 0.3774 - val_loss: 7.4702 - val_accuracy: 0.3058\n",
      "Epoch 57/500\n",
      " - 1s - loss: 1.7571 - accuracy: 0.3678 - val_loss: 7.7121 - val_accuracy: 0.2992\n",
      "Epoch 58/500\n",
      " - 1s - loss: 1.7525 - accuracy: 0.3608 - val_loss: 7.5893 - val_accuracy: 0.3281\n",
      "Epoch 59/500\n",
      " - 1s - loss: 1.7645 - accuracy: 0.3694 - val_loss: 7.6587 - val_accuracy: 0.2966\n",
      "Epoch 60/500\n",
      " - 0s - loss: 1.7404 - accuracy: 0.3628 - val_loss: 7.5773 - val_accuracy: 0.3110\n",
      "Epoch 61/500\n",
      " - 0s - loss: 1.7200 - accuracy: 0.3717 - val_loss: 7.6582 - val_accuracy: 0.3281\n",
      "Epoch 62/500\n",
      " - 0s - loss: 1.7160 - accuracy: 0.3749 - val_loss: 7.6015 - val_accuracy: 0.3136\n",
      "Epoch 63/500\n",
      " - 0s - loss: 1.7054 - accuracy: 0.3768 - val_loss: 7.6617 - val_accuracy: 0.2822\n",
      "Epoch 64/500\n",
      " - 0s - loss: 1.7273 - accuracy: 0.3722 - val_loss: 7.4574 - val_accuracy: 0.3425\n",
      "Epoch 65/500\n",
      " - 0s - loss: 1.7213 - accuracy: 0.3673 - val_loss: 7.4843 - val_accuracy: 0.3294\n",
      "Epoch 66/500\n",
      " - 0s - loss: 1.7481 - accuracy: 0.3780 - val_loss: 7.2887 - val_accuracy: 0.3268\n",
      "Epoch 67/500\n",
      " - 1s - loss: 1.7062 - accuracy: 0.3806 - val_loss: 7.4985 - val_accuracy: 0.3005\n",
      "Epoch 68/500\n",
      " - 1s - loss: 1.7131 - accuracy: 0.3849 - val_loss: 7.5826 - val_accuracy: 0.3281\n",
      "Epoch 69/500\n",
      " - 1s - loss: 1.7124 - accuracy: 0.3795 - val_loss: 7.7242 - val_accuracy: 0.3333\n",
      "Epoch 70/500\n",
      " - 1s - loss: 1.6862 - accuracy: 0.3813 - val_loss: 7.7337 - val_accuracy: 0.3005\n",
      "Epoch 71/500\n",
      " - 1s - loss: 1.7837 - accuracy: 0.3641 - val_loss: 7.6252 - val_accuracy: 0.3320\n",
      "Epoch 72/500\n",
      " - 1s - loss: 1.7359 - accuracy: 0.3754 - val_loss: 7.6247 - val_accuracy: 0.3097\n",
      "Epoch 73/500\n",
      " - 1s - loss: 1.6670 - accuracy: 0.3862 - val_loss: 7.5228 - val_accuracy: 0.3425\n",
      "Epoch 74/500\n",
      " - 1s - loss: 1.6460 - accuracy: 0.3851 - val_loss: 7.8158 - val_accuracy: 0.3373\n",
      "Epoch 75/500\n",
      " - 1s - loss: 1.6457 - accuracy: 0.3879 - val_loss: 8.1201 - val_accuracy: 0.3228\n",
      "Epoch 76/500\n",
      " - 1s - loss: 1.6467 - accuracy: 0.3924 - val_loss: 7.8305 - val_accuracy: 0.3071\n",
      "Epoch 77/500\n",
      " - 1s - loss: 1.6163 - accuracy: 0.4024 - val_loss: 7.9321 - val_accuracy: 0.3084\n",
      "Epoch 78/500\n",
      " - 1s - loss: 1.6411 - accuracy: 0.3917 - val_loss: 7.9361 - val_accuracy: 0.3556\n",
      "Epoch 79/500\n",
      " - 1s - loss: 1.6255 - accuracy: 0.4067 - val_loss: 7.9159 - val_accuracy: 0.3399\n",
      "Epoch 80/500\n",
      " - 1s - loss: 1.6270 - accuracy: 0.3901 - val_loss: 7.6356 - val_accuracy: 0.3451\n",
      "Epoch 81/500\n",
      " - 1s - loss: 1.6203 - accuracy: 0.4018 - val_loss: 7.7642 - val_accuracy: 0.3176\n",
      "Epoch 82/500\n",
      " - 1s - loss: 1.6708 - accuracy: 0.3841 - val_loss: 7.7838 - val_accuracy: 0.3570\n",
      "Epoch 83/500\n",
      " - 1s - loss: 1.6262 - accuracy: 0.4082 - val_loss: 7.6613 - val_accuracy: 0.3478\n",
      "Epoch 84/500\n",
      " - 1s - loss: 1.6530 - accuracy: 0.3876 - val_loss: 7.8361 - val_accuracy: 0.3543\n",
      "Epoch 85/500\n",
      " - 0s - loss: 1.6301 - accuracy: 0.3994 - val_loss: 7.6442 - val_accuracy: 0.3360\n",
      "Epoch 86/500\n",
      " - 1s - loss: 1.6038 - accuracy: 0.4028 - val_loss: 7.9161 - val_accuracy: 0.3556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 87/500\n",
      " - 1s - loss: 1.6208 - accuracy: 0.3933 - val_loss: 7.7695 - val_accuracy: 0.3425\n",
      "Epoch 88/500\n",
      " - 0s - loss: 1.5941 - accuracy: 0.4003 - val_loss: 7.7979 - val_accuracy: 0.3517\n",
      "Epoch 89/500\n",
      " - 1s - loss: 1.6745 - accuracy: 0.3974 - val_loss: 7.7338 - val_accuracy: 0.3543\n",
      "Epoch 90/500\n",
      " - 1s - loss: 1.5564 - accuracy: 0.4151 - val_loss: 7.7964 - val_accuracy: 0.3281\n",
      "Epoch 91/500\n",
      " - 1s - loss: 1.5883 - accuracy: 0.4062 - val_loss: 7.8764 - val_accuracy: 0.3307\n",
      "Epoch 92/500\n",
      " - 1s - loss: 1.6797 - accuracy: 0.3835 - val_loss: 7.7425 - val_accuracy: 0.3438\n",
      "Epoch 93/500\n",
      " - 1s - loss: 1.6055 - accuracy: 0.4053 - val_loss: 7.9796 - val_accuracy: 0.3635\n",
      "Epoch 94/500\n",
      " - 1s - loss: 1.5368 - accuracy: 0.4219 - val_loss: 7.8154 - val_accuracy: 0.3583\n",
      "Epoch 95/500\n",
      " - 1s - loss: 1.5787 - accuracy: 0.4133 - val_loss: 8.3615 - val_accuracy: 0.3176\n",
      "Epoch 96/500\n",
      " - 1s - loss: 1.5782 - accuracy: 0.4048 - val_loss: 7.6810 - val_accuracy: 0.3766\n",
      "Epoch 97/500\n",
      " - 1s - loss: 1.5498 - accuracy: 0.4247 - val_loss: 8.0182 - val_accuracy: 0.3504\n",
      "Epoch 98/500\n",
      " - 1s - loss: 1.5679 - accuracy: 0.4136 - val_loss: 7.8526 - val_accuracy: 0.3675\n",
      "Epoch 99/500\n",
      " - 1s - loss: 1.5661 - accuracy: 0.4117 - val_loss: 8.0110 - val_accuracy: 0.3333\n",
      "Epoch 100/500\n",
      " - 1s - loss: 1.5339 - accuracy: 0.4240 - val_loss: 8.0119 - val_accuracy: 0.3530\n",
      "Epoch 101/500\n",
      " - 1s - loss: 1.5566 - accuracy: 0.4073 - val_loss: 8.1141 - val_accuracy: 0.3622\n",
      "Epoch 102/500\n",
      " - 1s - loss: 1.5087 - accuracy: 0.4250 - val_loss: 8.0698 - val_accuracy: 0.3412\n",
      "Epoch 103/500\n",
      " - 1s - loss: 1.5119 - accuracy: 0.4332 - val_loss: 8.0673 - val_accuracy: 0.3543\n",
      "Epoch 104/500\n",
      " - 1s - loss: 1.5412 - accuracy: 0.4100 - val_loss: 8.4315 - val_accuracy: 0.3714\n",
      "Epoch 105/500\n",
      " - 1s - loss: 1.5247 - accuracy: 0.4170 - val_loss: 8.0527 - val_accuracy: 0.3504\n",
      "Epoch 106/500\n",
      " - 0s - loss: 1.5128 - accuracy: 0.4229 - val_loss: 8.0759 - val_accuracy: 0.3543\n",
      "Epoch 107/500\n",
      " - 0s - loss: 1.4925 - accuracy: 0.4314 - val_loss: 8.3280 - val_accuracy: 0.3871\n",
      "Epoch 108/500\n",
      " - 0s - loss: 1.5327 - accuracy: 0.4267 - val_loss: 8.2666 - val_accuracy: 0.3543\n",
      "Epoch 109/500\n",
      " - 0s - loss: 1.5235 - accuracy: 0.4202 - val_loss: 7.9415 - val_accuracy: 0.3556\n",
      "Epoch 110/500\n",
      " - 1s - loss: 1.7630 - accuracy: 0.3705 - val_loss: 7.6690 - val_accuracy: 0.3543\n",
      "Epoch 111/500\n",
      " - 1s - loss: 1.5567 - accuracy: 0.4234 - val_loss: 7.4967 - val_accuracy: 0.3688\n",
      "Epoch 112/500\n",
      " - 1s - loss: 1.4859 - accuracy: 0.4310 - val_loss: 7.6727 - val_accuracy: 0.3583\n",
      "Epoch 113/500\n",
      " - 1s - loss: 1.4936 - accuracy: 0.4320 - val_loss: 7.9400 - val_accuracy: 0.3740\n",
      "Epoch 114/500\n",
      " - 1s - loss: 1.4918 - accuracy: 0.4264 - val_loss: 8.1515 - val_accuracy: 0.3438\n",
      "Epoch 115/500\n",
      " - 1s - loss: 1.4698 - accuracy: 0.4370 - val_loss: 8.0932 - val_accuracy: 0.3622\n",
      "Epoch 116/500\n",
      " - 1s - loss: 1.5014 - accuracy: 0.4281 - val_loss: 8.2367 - val_accuracy: 0.3635\n",
      "Epoch 117/500\n",
      " - 1s - loss: 1.4815 - accuracy: 0.4323 - val_loss: 8.1324 - val_accuracy: 0.3675\n",
      "Epoch 118/500\n",
      " - 1s - loss: 1.4582 - accuracy: 0.4365 - val_loss: 8.3320 - val_accuracy: 0.3740\n",
      "Epoch 119/500\n",
      " - 1s - loss: 1.5964 - accuracy: 0.4067 - val_loss: 8.0272 - val_accuracy: 0.3215\n",
      "Epoch 120/500\n",
      " - 1s - loss: 1.7604 - accuracy: 0.3625 - val_loss: 7.8813 - val_accuracy: 0.3570\n",
      "Epoch 121/500\n",
      " - 1s - loss: 1.5390 - accuracy: 0.4256 - val_loss: 7.6852 - val_accuracy: 0.3688\n",
      "Epoch 122/500\n",
      " - 1s - loss: 1.4700 - accuracy: 0.4428 - val_loss: 7.9228 - val_accuracy: 0.3543\n",
      "Epoch 123/500\n",
      " - 1s - loss: 1.4393 - accuracy: 0.4388 - val_loss: 7.9193 - val_accuracy: 0.3963\n",
      "Epoch 124/500\n",
      " - 1s - loss: 1.4540 - accuracy: 0.4445 - val_loss: 8.1872 - val_accuracy: 0.3832\n",
      "Epoch 125/500\n",
      " - 1s - loss: 1.4716 - accuracy: 0.4388 - val_loss: 8.1214 - val_accuracy: 0.3609\n",
      "Epoch 126/500\n",
      " - 1s - loss: 1.4690 - accuracy: 0.4361 - val_loss: 8.1749 - val_accuracy: 0.3465\n",
      "Epoch 127/500\n",
      " - 1s - loss: 1.4311 - accuracy: 0.4406 - val_loss: 8.3863 - val_accuracy: 0.3819\n",
      "Epoch 128/500\n",
      " - 1s - loss: 1.4744 - accuracy: 0.4215 - val_loss: 8.4272 - val_accuracy: 0.3609\n",
      "Epoch 129/500\n",
      " - 1s - loss: 1.4328 - accuracy: 0.4362 - val_loss: 8.4613 - val_accuracy: 0.3845\n",
      "Epoch 130/500\n",
      " - 1s - loss: 1.4612 - accuracy: 0.4425 - val_loss: 8.2911 - val_accuracy: 0.3425\n",
      "Epoch 131/500\n",
      " - 1s - loss: 1.4420 - accuracy: 0.4370 - val_loss: 8.4756 - val_accuracy: 0.3688\n",
      "Epoch 132/500\n",
      " - 1s - loss: 1.4429 - accuracy: 0.4418 - val_loss: 8.1422 - val_accuracy: 0.3517\n",
      "Epoch 133/500\n",
      " - 1s - loss: 1.4766 - accuracy: 0.4380 - val_loss: 8.1301 - val_accuracy: 0.3241\n",
      "Epoch 134/500\n",
      " - 1s - loss: 1.4540 - accuracy: 0.4409 - val_loss: 8.3992 - val_accuracy: 0.3701\n",
      "Epoch 135/500\n",
      " - 1s - loss: 1.4323 - accuracy: 0.4475 - val_loss: 8.3243 - val_accuracy: 0.3425\n",
      "Epoch 136/500\n",
      " - 1s - loss: 1.4628 - accuracy: 0.4413 - val_loss: 8.4556 - val_accuracy: 0.3661\n",
      "Epoch 137/500\n",
      " - 1s - loss: 1.4717 - accuracy: 0.4394 - val_loss: 8.4143 - val_accuracy: 0.3688\n",
      "Epoch 138/500\n",
      " - 1s - loss: 1.4102 - accuracy: 0.4533 - val_loss: 8.2918 - val_accuracy: 0.3583\n",
      "Epoch 139/500\n",
      " - 1s - loss: 1.4331 - accuracy: 0.4467 - val_loss: 8.6508 - val_accuracy: 0.3478\n",
      "Epoch 140/500\n",
      " - 1s - loss: 1.4112 - accuracy: 0.4616 - val_loss: 8.6952 - val_accuracy: 0.3858\n",
      "Epoch 141/500\n",
      " - 1s - loss: 1.4121 - accuracy: 0.4429 - val_loss: 9.0718 - val_accuracy: 0.3556\n",
      "Epoch 142/500\n",
      " - 0s - loss: 1.5000 - accuracy: 0.4199 - val_loss: 8.4657 - val_accuracy: 0.3478\n",
      "Epoch 143/500\n",
      " - 0s - loss: 1.4147 - accuracy: 0.4480 - val_loss: 8.5812 - val_accuracy: 0.3530\n",
      "Epoch 144/500\n",
      " - 0s - loss: 1.3884 - accuracy: 0.4591 - val_loss: 8.7905 - val_accuracy: 0.3753\n",
      "Epoch 145/500\n",
      " - 0s - loss: 1.4634 - accuracy: 0.4407 - val_loss: 8.5381 - val_accuracy: 0.3635\n",
      "Epoch 146/500\n",
      " - 0s - loss: 1.3906 - accuracy: 0.4537 - val_loss: 8.9417 - val_accuracy: 0.3727\n",
      "Epoch 147/500\n",
      " - 1s - loss: 1.3940 - accuracy: 0.4495 - val_loss: 8.4254 - val_accuracy: 0.3753\n",
      "Epoch 148/500\n",
      " - 1s - loss: 1.3782 - accuracy: 0.4584 - val_loss: 8.8173 - val_accuracy: 0.3806\n",
      "Epoch 149/500\n",
      " - 1s - loss: 1.4640 - accuracy: 0.4510 - val_loss: 8.2702 - val_accuracy: 0.3635\n",
      "Epoch 150/500\n",
      " - 1s - loss: 1.4546 - accuracy: 0.4460 - val_loss: 8.4563 - val_accuracy: 0.3360\n",
      "Epoch 151/500\n",
      " - 1s - loss: 1.5123 - accuracy: 0.4409 - val_loss: 8.1120 - val_accuracy: 0.3832\n",
      "Epoch 152/500\n",
      " - 1s - loss: 1.4292 - accuracy: 0.4550 - val_loss: 8.2070 - val_accuracy: 0.3675\n",
      "Epoch 153/500\n",
      " - 1s - loss: 1.3862 - accuracy: 0.4607 - val_loss: 8.5983 - val_accuracy: 0.3740\n",
      "Epoch 154/500\n",
      " - 1s - loss: 1.3921 - accuracy: 0.4539 - val_loss: 8.3256 - val_accuracy: 0.3911\n",
      "Epoch 155/500\n",
      " - 1s - loss: 1.3788 - accuracy: 0.4651 - val_loss: 8.9448 - val_accuracy: 0.3425\n",
      "Epoch 156/500\n",
      " - 1s - loss: 1.3565 - accuracy: 0.4802 - val_loss: 8.3718 - val_accuracy: 0.3727\n",
      "Epoch 157/500\n",
      " - 1s - loss: 1.3569 - accuracy: 0.4707 - val_loss: 8.9576 - val_accuracy: 0.3714\n",
      "Epoch 158/500\n",
      " - 1s - loss: 1.3626 - accuracy: 0.4733 - val_loss: 8.6553 - val_accuracy: 0.3504\n",
      "Epoch 159/500\n",
      " - 1s - loss: 1.3563 - accuracy: 0.4637 - val_loss: 8.6171 - val_accuracy: 0.3753\n",
      "Epoch 160/500\n",
      " - 1s - loss: 1.3714 - accuracy: 0.4623 - val_loss: 8.8194 - val_accuracy: 0.3530\n",
      "Epoch 161/500\n",
      " - 1s - loss: 1.3717 - accuracy: 0.4694 - val_loss: 8.9549 - val_accuracy: 0.3753\n",
      "Epoch 162/500\n",
      " - 1s - loss: 1.3517 - accuracy: 0.4658 - val_loss: 8.8999 - val_accuracy: 0.3609\n",
      "Epoch 163/500\n",
      " - 1s - loss: 1.3890 - accuracy: 0.4536 - val_loss: 9.2562 - val_accuracy: 0.3845\n",
      "Epoch 164/500\n",
      " - 1s - loss: 1.3747 - accuracy: 0.4623 - val_loss: 8.9609 - val_accuracy: 0.3635\n",
      "Epoch 165/500\n",
      " - 1s - loss: 1.3984 - accuracy: 0.4448 - val_loss: 8.9403 - val_accuracy: 0.3753\n",
      "Epoch 166/500\n",
      " - 0s - loss: 1.3446 - accuracy: 0.4691 - val_loss: 8.9042 - val_accuracy: 0.3438\n",
      "Epoch 167/500\n",
      " - 0s - loss: 1.4164 - accuracy: 0.4467 - val_loss: 9.2365 - val_accuracy: 0.3556\n",
      "Epoch 168/500\n",
      " - 0s - loss: 1.4086 - accuracy: 0.4635 - val_loss: 8.4503 - val_accuracy: 0.3543\n",
      "Epoch 169/500\n",
      " - 0s - loss: 1.4580 - accuracy: 0.4434 - val_loss: 8.5145 - val_accuracy: 0.3661\n",
      "Epoch 170/500\n",
      " - 0s - loss: 1.3925 - accuracy: 0.4434 - val_loss: 8.7368 - val_accuracy: 0.3753\n",
      "Epoch 171/500\n",
      " - 0s - loss: 1.3466 - accuracy: 0.4730 - val_loss: 8.9204 - val_accuracy: 0.3688\n",
      "Epoch 172/500\n",
      " - 1s - loss: 1.4464 - accuracy: 0.4342 - val_loss: 9.1272 - val_accuracy: 0.3950\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/500\n",
      " - 1s - loss: 1.4275 - accuracy: 0.4450 - val_loss: 8.8607 - val_accuracy: 0.3753\n",
      "Epoch 174/500\n",
      " - 1s - loss: 1.3824 - accuracy: 0.4653 - val_loss: 8.7089 - val_accuracy: 0.3898\n",
      "Epoch 175/500\n",
      " - 1s - loss: 1.3625 - accuracy: 0.4758 - val_loss: 8.5418 - val_accuracy: 0.3832\n",
      "Epoch 176/500\n",
      " - 1s - loss: 1.3451 - accuracy: 0.4745 - val_loss: 8.6606 - val_accuracy: 0.3688\n",
      "Epoch 177/500\n",
      " - 1s - loss: 1.3515 - accuracy: 0.4619 - val_loss: 8.9939 - val_accuracy: 0.3832\n",
      "Epoch 178/500\n",
      " - 1s - loss: 1.2798 - accuracy: 0.4877 - val_loss: 9.0181 - val_accuracy: 0.3780\n",
      "Epoch 179/500\n",
      " - 1s - loss: 1.3420 - accuracy: 0.4803 - val_loss: 8.9021 - val_accuracy: 0.3727\n",
      "Epoch 180/500\n",
      " - 1s - loss: 1.3738 - accuracy: 0.4599 - val_loss: 8.6860 - val_accuracy: 0.4042\n",
      "Epoch 181/500\n",
      " - 1s - loss: 1.3124 - accuracy: 0.4796 - val_loss: 8.8956 - val_accuracy: 0.3661\n",
      "Epoch 182/500\n",
      " - 1s - loss: 1.4788 - accuracy: 0.4390 - val_loss: 8.3954 - val_accuracy: 0.3675\n",
      "Epoch 183/500\n",
      " - 1s - loss: 1.3282 - accuracy: 0.4731 - val_loss: 8.7736 - val_accuracy: 0.3885\n",
      "Epoch 184/500\n",
      " - 1s - loss: 1.3067 - accuracy: 0.4777 - val_loss: 9.0971 - val_accuracy: 0.3806\n",
      "Epoch 185/500\n",
      " - 1s - loss: 1.3221 - accuracy: 0.4764 - val_loss: 9.0762 - val_accuracy: 0.3596\n",
      "Epoch 186/500\n",
      " - 1s - loss: 1.3115 - accuracy: 0.4750 - val_loss: 9.0045 - val_accuracy: 0.4134\n",
      "Epoch 187/500\n",
      " - 0s - loss: 1.3006 - accuracy: 0.4794 - val_loss: 9.3473 - val_accuracy: 0.3924\n",
      "Epoch 188/500\n",
      " - 0s - loss: 1.5397 - accuracy: 0.4345 - val_loss: 8.6627 - val_accuracy: 0.3727\n",
      "Epoch 189/500\n",
      " - 0s - loss: 1.3348 - accuracy: 0.4825 - val_loss: 8.8014 - val_accuracy: 0.3753\n",
      "Epoch 190/500\n",
      " - 0s - loss: 1.2941 - accuracy: 0.4904 - val_loss: 8.8942 - val_accuracy: 0.3963\n",
      "Epoch 191/500\n",
      " - 0s - loss: 1.2658 - accuracy: 0.4984 - val_loss: 9.1868 - val_accuracy: 0.3911\n",
      "Epoch 192/500\n",
      " - 0s - loss: 1.3123 - accuracy: 0.4721 - val_loss: 9.5720 - val_accuracy: 0.3740\n",
      "Epoch 193/500\n",
      " - 1s - loss: 1.2818 - accuracy: 0.4934 - val_loss: 9.0498 - val_accuracy: 0.3806\n",
      "Epoch 194/500\n",
      " - 1s - loss: 1.2854 - accuracy: 0.4857 - val_loss: 8.9246 - val_accuracy: 0.3583\n",
      "Epoch 195/500\n",
      " - 0s - loss: 1.3596 - accuracy: 0.4750 - val_loss: 9.2355 - val_accuracy: 0.3570\n",
      "Epoch 196/500\n",
      " - 1s - loss: 1.3073 - accuracy: 0.4845 - val_loss: 8.9974 - val_accuracy: 0.3753\n",
      "Epoch 197/500\n",
      " - 1s - loss: 1.2831 - accuracy: 0.4800 - val_loss: 9.1682 - val_accuracy: 0.3570\n",
      "Epoch 198/500\n",
      " - 1s - loss: 1.3053 - accuracy: 0.4720 - val_loss: 9.2254 - val_accuracy: 0.3622\n",
      "Epoch 199/500\n",
      " - 0s - loss: 1.3074 - accuracy: 0.4734 - val_loss: 9.5852 - val_accuracy: 0.3675\n",
      "Epoch 200/500\n",
      " - 0s - loss: 1.2508 - accuracy: 0.4928 - val_loss: 9.2537 - val_accuracy: 0.3990\n",
      "Epoch 201/500\n",
      " - 0s - loss: 1.3163 - accuracy: 0.4860 - val_loss: 9.8974 - val_accuracy: 0.3609\n",
      "Epoch 202/500\n",
      " - 0s - loss: 1.5016 - accuracy: 0.4469 - val_loss: 8.5195 - val_accuracy: 0.3425\n",
      "Epoch 203/500\n",
      " - 1s - loss: 1.3266 - accuracy: 0.4793 - val_loss: 9.1590 - val_accuracy: 0.3465\n",
      "Epoch 204/500\n",
      " - 1s - loss: 1.2678 - accuracy: 0.4899 - val_loss: 8.7015 - val_accuracy: 0.3701\n",
      "Epoch 205/500\n",
      " - 1s - loss: 1.2552 - accuracy: 0.4856 - val_loss: 8.9692 - val_accuracy: 0.3740\n",
      "Epoch 206/500\n",
      " - 1s - loss: 1.2493 - accuracy: 0.4927 - val_loss: 8.9969 - val_accuracy: 0.3806\n",
      "Epoch 207/500\n",
      " - 1s - loss: 1.3273 - accuracy: 0.4759 - val_loss: 9.3267 - val_accuracy: 0.3255\n",
      "Epoch 208/500\n",
      " - 1s - loss: 1.3647 - accuracy: 0.4619 - val_loss: 8.9028 - val_accuracy: 0.3832\n",
      "Epoch 209/500\n",
      " - 1s - loss: 1.3905 - accuracy: 0.4590 - val_loss: 8.9924 - val_accuracy: 0.3845\n",
      "Epoch 210/500\n",
      " - 1s - loss: 1.2928 - accuracy: 0.4791 - val_loss: 9.0134 - val_accuracy: 0.3832\n",
      "Epoch 211/500\n",
      " - 1s - loss: 1.2731 - accuracy: 0.5006 - val_loss: 9.1510 - val_accuracy: 0.4042\n",
      "Epoch 212/500\n",
      " - 0s - loss: 1.2745 - accuracy: 0.4928 - val_loss: 9.4007 - val_accuracy: 0.3911\n",
      "Epoch 213/500\n",
      " - 0s - loss: 1.2604 - accuracy: 0.4975 - val_loss: 9.0046 - val_accuracy: 0.3911\n",
      "Epoch 214/500\n",
      " - 0s - loss: 1.3050 - accuracy: 0.4809 - val_loss: 9.1382 - val_accuracy: 0.3504\n",
      "Epoch 215/500\n",
      " - 0s - loss: 1.2983 - accuracy: 0.4842 - val_loss: 9.1052 - val_accuracy: 0.4003\n",
      "Epoch 216/500\n",
      " - 0s - loss: 1.2517 - accuracy: 0.5012 - val_loss: 9.5692 - val_accuracy: 0.3845\n",
      "Epoch 217/500\n",
      " - 1s - loss: 1.2292 - accuracy: 0.5001 - val_loss: 10.1109 - val_accuracy: 0.3727\n",
      "Epoch 218/500\n",
      " - 1s - loss: 1.2395 - accuracy: 0.4975 - val_loss: 9.5857 - val_accuracy: 0.3858\n",
      "Epoch 219/500\n",
      " - 0s - loss: 1.2392 - accuracy: 0.5013 - val_loss: 9.3334 - val_accuracy: 0.3793\n",
      "Epoch 220/500\n",
      " - 1s - loss: 1.2508 - accuracy: 0.4936 - val_loss: 9.4305 - val_accuracy: 0.3661\n",
      "Epoch 221/500\n",
      " - 0s - loss: 1.2657 - accuracy: 0.4958 - val_loss: 9.6464 - val_accuracy: 0.3924\n",
      "Epoch 222/500\n",
      " - 1s - loss: 1.2584 - accuracy: 0.4888 - val_loss: 9.5851 - val_accuracy: 0.3701\n",
      "Epoch 223/500\n",
      " - 0s - loss: 1.2954 - accuracy: 0.4883 - val_loss: 9.3001 - val_accuracy: 0.4029\n",
      "Epoch 224/500\n",
      " - 0s - loss: 1.2969 - accuracy: 0.4869 - val_loss: 9.2299 - val_accuracy: 0.4003\n",
      "Epoch 225/500\n",
      " - 0s - loss: 1.2707 - accuracy: 0.5025 - val_loss: 9.3069 - val_accuracy: 0.3819\n",
      "Epoch 226/500\n",
      " - 0s - loss: 1.3271 - accuracy: 0.4829 - val_loss: 9.6813 - val_accuracy: 0.3609\n",
      "Epoch 227/500\n",
      " - 0s - loss: 1.2576 - accuracy: 0.4958 - val_loss: 9.3936 - val_accuracy: 0.4081\n",
      "Epoch 228/500\n",
      " - 0s - loss: 1.1995 - accuracy: 0.5095 - val_loss: 9.2325 - val_accuracy: 0.4055\n",
      "Epoch 229/500\n",
      " - 0s - loss: 1.2803 - accuracy: 0.4834 - val_loss: 9.1957 - val_accuracy: 0.3950\n",
      "Epoch 230/500\n",
      " - 0s - loss: 1.2381 - accuracy: 0.4982 - val_loss: 9.2240 - val_accuracy: 0.3832\n",
      "Epoch 231/500\n",
      " - 0s - loss: 1.2133 - accuracy: 0.5147 - val_loss: 9.8899 - val_accuracy: 0.3740\n",
      "Epoch 232/500\n",
      " - 0s - loss: 1.2422 - accuracy: 0.4930 - val_loss: 9.7921 - val_accuracy: 0.3688\n",
      "Epoch 233/500\n",
      " - 0s - loss: 1.2105 - accuracy: 0.5080 - val_loss: 9.4644 - val_accuracy: 0.4173\n",
      "Epoch 234/500\n",
      " - 1s - loss: 1.2390 - accuracy: 0.5109 - val_loss: 9.8905 - val_accuracy: 0.3871\n",
      "Epoch 235/500\n",
      " - 1s - loss: 1.2232 - accuracy: 0.5080 - val_loss: 9.6457 - val_accuracy: 0.3990\n",
      "Epoch 236/500\n",
      " - 1s - loss: 1.2598 - accuracy: 0.4968 - val_loss: 9.7626 - val_accuracy: 0.3924\n",
      "Epoch 237/500\n",
      " - 1s - loss: 1.2139 - accuracy: 0.5077 - val_loss: 10.0293 - val_accuracy: 0.3806\n",
      "Epoch 238/500\n",
      " - 1s - loss: 1.2857 - accuracy: 0.4771 - val_loss: 9.5342 - val_accuracy: 0.3924\n",
      "Epoch 239/500\n",
      " - 1s - loss: 1.2233 - accuracy: 0.5023 - val_loss: 9.7701 - val_accuracy: 0.3753\n",
      "Epoch 240/500\n",
      " - 1s - loss: 1.2149 - accuracy: 0.4993 - val_loss: 9.6776 - val_accuracy: 0.3753\n",
      "Epoch 241/500\n",
      " - 1s - loss: 1.3706 - accuracy: 0.4860 - val_loss: 9.6580 - val_accuracy: 0.3609\n",
      "Epoch 242/500\n",
      " - 1s - loss: 1.2939 - accuracy: 0.4889 - val_loss: 9.3677 - val_accuracy: 0.3753\n",
      "Epoch 243/500\n",
      " - 1s - loss: 1.2132 - accuracy: 0.5149 - val_loss: 9.3716 - val_accuracy: 0.3596\n",
      "Epoch 244/500\n",
      " - 1s - loss: 1.1964 - accuracy: 0.5055 - val_loss: 9.5278 - val_accuracy: 0.3688\n",
      "Epoch 245/500\n",
      " - 0s - loss: 1.3063 - accuracy: 0.4848 - val_loss: 9.6460 - val_accuracy: 0.3793\n",
      "Epoch 246/500\n",
      " - 0s - loss: 1.2127 - accuracy: 0.4965 - val_loss: 9.5905 - val_accuracy: 0.3898\n",
      "Epoch 247/500\n",
      " - 0s - loss: 1.1751 - accuracy: 0.5198 - val_loss: 9.8248 - val_accuracy: 0.3963\n",
      "Epoch 248/500\n",
      " - 0s - loss: 1.2064 - accuracy: 0.5158 - val_loss: 9.9432 - val_accuracy: 0.3780\n",
      "Epoch 249/500\n",
      " - 0s - loss: 1.2687 - accuracy: 0.4891 - val_loss: 9.8626 - val_accuracy: 0.3648\n",
      "Epoch 250/500\n",
      " - 0s - loss: 1.2565 - accuracy: 0.4917 - val_loss: 9.6001 - val_accuracy: 0.3963\n",
      "Epoch 251/500\n",
      " - 1s - loss: 1.2059 - accuracy: 0.5155 - val_loss: 9.9420 - val_accuracy: 0.3806\n",
      "Epoch 252/500\n",
      " - 1s - loss: 1.1825 - accuracy: 0.5127 - val_loss: 9.6944 - val_accuracy: 0.3950\n",
      "Epoch 253/500\n",
      " - 1s - loss: 1.2136 - accuracy: 0.5117 - val_loss: 9.4547 - val_accuracy: 0.3727\n",
      "Epoch 254/500\n",
      " - 1s - loss: 1.1730 - accuracy: 0.5196 - val_loss: 9.7478 - val_accuracy: 0.3661\n",
      "Epoch 255/500\n",
      " - 1s - loss: 1.1829 - accuracy: 0.5142 - val_loss: 9.9513 - val_accuracy: 0.4186\n",
      "Epoch 256/500\n",
      " - 1s - loss: 1.1860 - accuracy: 0.5238 - val_loss: 9.6743 - val_accuracy: 0.3845\n",
      "Epoch 257/500\n",
      " - 1s - loss: 1.2788 - accuracy: 0.4953 - val_loss: 10.2465 - val_accuracy: 0.3714\n",
      "Epoch 258/500\n",
      " - 1s - loss: 1.1844 - accuracy: 0.5070 - val_loss: 9.4340 - val_accuracy: 0.3963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 259/500\n",
      " - 1s - loss: 1.1709 - accuracy: 0.5190 - val_loss: 9.8595 - val_accuracy: 0.4029\n",
      "Epoch 260/500\n",
      " - 1s - loss: 1.1346 - accuracy: 0.5298 - val_loss: 10.1996 - val_accuracy: 0.3596\n",
      "Epoch 261/500\n",
      " - 1s - loss: 1.1836 - accuracy: 0.4962 - val_loss: 9.7006 - val_accuracy: 0.4108\n",
      "Epoch 262/500\n",
      " - 0s - loss: 1.2184 - accuracy: 0.5038 - val_loss: 9.7841 - val_accuracy: 0.3845\n",
      "Epoch 263/500\n",
      " - 0s - loss: 1.1762 - accuracy: 0.5105 - val_loss: 9.5011 - val_accuracy: 0.4108\n",
      "Epoch 264/500\n",
      " - 0s - loss: 1.1639 - accuracy: 0.5152 - val_loss: 10.0218 - val_accuracy: 0.3950\n",
      "Epoch 265/500\n",
      " - 0s - loss: 1.1774 - accuracy: 0.5058 - val_loss: 10.2466 - val_accuracy: 0.4147\n",
      "Epoch 266/500\n",
      " - 0s - loss: 1.1709 - accuracy: 0.5134 - val_loss: 10.5688 - val_accuracy: 0.3950\n",
      "Epoch 267/500\n",
      " - 0s - loss: 1.2174 - accuracy: 0.5015 - val_loss: 10.8105 - val_accuracy: 0.3819\n",
      "Epoch 268/500\n",
      " - 0s - loss: 1.1794 - accuracy: 0.5112 - val_loss: 9.7725 - val_accuracy: 0.3898\n",
      "Epoch 269/500\n",
      " - 0s - loss: 1.1890 - accuracy: 0.5174 - val_loss: 10.2664 - val_accuracy: 0.4068\n",
      "Epoch 270/500\n",
      " - 0s - loss: 1.1877 - accuracy: 0.5142 - val_loss: 10.2989 - val_accuracy: 0.3635\n",
      "Epoch 271/500\n",
      " - 1s - loss: 1.2024 - accuracy: 0.5096 - val_loss: 9.8931 - val_accuracy: 0.4108\n",
      "Epoch 272/500\n",
      " - 0s - loss: 1.1495 - accuracy: 0.5239 - val_loss: 10.2627 - val_accuracy: 0.4042\n",
      "Epoch 273/500\n",
      " - 0s - loss: 1.1909 - accuracy: 0.5044 - val_loss: 9.7656 - val_accuracy: 0.3819\n",
      "Epoch 274/500\n",
      " - 0s - loss: 1.1891 - accuracy: 0.5108 - val_loss: 10.6478 - val_accuracy: 0.3871\n",
      "Epoch 275/500\n",
      " - 0s - loss: 1.2241 - accuracy: 0.5009 - val_loss: 10.0476 - val_accuracy: 0.4016\n",
      "Epoch 276/500\n",
      " - 0s - loss: 1.1684 - accuracy: 0.5185 - val_loss: 10.7240 - val_accuracy: 0.3661\n",
      "Epoch 277/500\n",
      " - 0s - loss: 1.2225 - accuracy: 0.5051 - val_loss: 10.4228 - val_accuracy: 0.3858\n",
      "Epoch 278/500\n",
      " - 1s - loss: 1.2367 - accuracy: 0.5050 - val_loss: 10.4736 - val_accuracy: 0.3556\n",
      "Epoch 279/500\n",
      " - 1s - loss: 1.3250 - accuracy: 0.4743 - val_loss: 9.8193 - val_accuracy: 0.4160\n",
      "Epoch 280/500\n",
      " - 1s - loss: 1.1626 - accuracy: 0.5219 - val_loss: 9.9386 - val_accuracy: 0.4042\n",
      "Epoch 281/500\n",
      " - 1s - loss: 1.1536 - accuracy: 0.5156 - val_loss: 9.9125 - val_accuracy: 0.3911\n",
      "Epoch 282/500\n",
      " - 1s - loss: 1.1014 - accuracy: 0.5404 - val_loss: 10.3834 - val_accuracy: 0.3976\n",
      "Epoch 283/500\n",
      " - 1s - loss: 1.1253 - accuracy: 0.5301 - val_loss: 10.3415 - val_accuracy: 0.4081\n",
      "Epoch 284/500\n",
      " - 1s - loss: 1.1503 - accuracy: 0.5229 - val_loss: 10.0920 - val_accuracy: 0.4055\n",
      "Epoch 285/500\n",
      " - 1s - loss: 1.1575 - accuracy: 0.5260 - val_loss: 10.1749 - val_accuracy: 0.3780\n",
      "Epoch 286/500\n",
      " - 0s - loss: 1.1311 - accuracy: 0.5321 - val_loss: 10.2987 - val_accuracy: 0.3661\n",
      "Epoch 287/500\n",
      " - 0s - loss: 1.1275 - accuracy: 0.5317 - val_loss: 10.5931 - val_accuracy: 0.3727\n",
      "Epoch 288/500\n",
      " - 0s - loss: 1.1447 - accuracy: 0.5225 - val_loss: 10.5597 - val_accuracy: 0.3609\n",
      "Epoch 289/500\n",
      " - 0s - loss: 1.1019 - accuracy: 0.5398 - val_loss: 11.4038 - val_accuracy: 0.3885\n",
      "Epoch 290/500\n",
      " - 0s - loss: 1.1729 - accuracy: 0.5115 - val_loss: 9.9762 - val_accuracy: 0.3727\n",
      "Epoch 291/500\n",
      " - 0s - loss: 1.2139 - accuracy: 0.5019 - val_loss: 10.5230 - val_accuracy: 0.3609\n",
      "Epoch 292/500\n",
      " - 0s - loss: 1.1287 - accuracy: 0.5251 - val_loss: 10.6014 - val_accuracy: 0.4081\n",
      "Epoch 293/500\n",
      " - 1s - loss: 1.1739 - accuracy: 0.5244 - val_loss: 10.0888 - val_accuracy: 0.3885\n",
      "Epoch 294/500\n",
      " - 0s - loss: 1.1312 - accuracy: 0.5347 - val_loss: 10.4874 - val_accuracy: 0.3911\n",
      "Epoch 295/500\n",
      " - 0s - loss: 1.1271 - accuracy: 0.5315 - val_loss: 10.0745 - val_accuracy: 0.3858\n",
      "Epoch 296/500\n",
      " - 0s - loss: 1.1387 - accuracy: 0.5242 - val_loss: 10.2898 - val_accuracy: 0.3963\n",
      "Epoch 297/500\n",
      " - 1s - loss: 1.1014 - accuracy: 0.5330 - val_loss: 10.5694 - val_accuracy: 0.4226\n",
      "Epoch 298/500\n",
      " - 1s - loss: 1.1464 - accuracy: 0.5311 - val_loss: 10.6986 - val_accuracy: 0.4003\n",
      "Epoch 299/500\n",
      " - 1s - loss: 1.2395 - accuracy: 0.5126 - val_loss: 9.5198 - val_accuracy: 0.3661\n",
      "Epoch 300/500\n",
      " - 1s - loss: 1.2759 - accuracy: 0.4882 - val_loss: 10.2197 - val_accuracy: 0.3675\n",
      "Epoch 301/500\n",
      " - 1s - loss: 1.1361 - accuracy: 0.5127 - val_loss: 10.3252 - val_accuracy: 0.4108\n",
      "Epoch 302/500\n",
      " - 1s - loss: 1.1468 - accuracy: 0.5194 - val_loss: 10.5123 - val_accuracy: 0.3819\n",
      "Epoch 303/500\n",
      " - 1s - loss: 1.0705 - accuracy: 0.5438 - val_loss: 10.3770 - val_accuracy: 0.4186\n",
      "Epoch 304/500\n",
      " - 1s - loss: 1.0895 - accuracy: 0.5451 - val_loss: 10.9620 - val_accuracy: 0.4003\n",
      "Epoch 305/500\n",
      " - 1s - loss: 1.1541 - accuracy: 0.5165 - val_loss: 10.9791 - val_accuracy: 0.3832\n",
      "Epoch 306/500\n",
      " - 0s - loss: 1.1533 - accuracy: 0.5257 - val_loss: 10.9163 - val_accuracy: 0.4173\n",
      "Epoch 307/500\n",
      " - 0s - loss: 1.1383 - accuracy: 0.5215 - val_loss: 10.7258 - val_accuracy: 0.3596\n",
      "Epoch 308/500\n",
      " - 0s - loss: 1.5494 - accuracy: 0.4460 - val_loss: 10.3445 - val_accuracy: 0.2441\n",
      "Epoch 309/500\n",
      " - 0s - loss: 1.7400 - accuracy: 0.4384 - val_loss: 8.4713 - val_accuracy: 0.3727\n",
      "Epoch 310/500\n",
      " - 0s - loss: 1.1818 - accuracy: 0.5359 - val_loss: 8.5324 - val_accuracy: 0.3898\n",
      "Epoch 311/500\n",
      " - 0s - loss: 1.1047 - accuracy: 0.5375 - val_loss: 9.1630 - val_accuracy: 0.4291\n",
      "Epoch 312/500\n",
      " - 1s - loss: 1.0796 - accuracy: 0.5489 - val_loss: 9.5201 - val_accuracy: 0.4252\n",
      "Epoch 313/500\n",
      " - 1s - loss: 1.0596 - accuracy: 0.5501 - val_loss: 9.8561 - val_accuracy: 0.3806\n",
      "Epoch 314/500\n",
      " - 1s - loss: 1.1053 - accuracy: 0.5347 - val_loss: 10.0281 - val_accuracy: 0.3648\n",
      "Epoch 315/500\n",
      " - 1s - loss: 1.1048 - accuracy: 0.5274 - val_loss: 10.2967 - val_accuracy: 0.3976\n",
      "Epoch 316/500\n",
      " - 1s - loss: 1.0999 - accuracy: 0.5299 - val_loss: 9.7696 - val_accuracy: 0.3924\n",
      "Epoch 317/500\n",
      " - 1s - loss: 1.1078 - accuracy: 0.5330 - val_loss: 10.4939 - val_accuracy: 0.3661\n",
      "Epoch 318/500\n",
      " - 1s - loss: 1.1154 - accuracy: 0.5315 - val_loss: 10.3348 - val_accuracy: 0.3688\n",
      "Epoch 319/500\n",
      " - 1s - loss: 1.0666 - accuracy: 0.5451 - val_loss: 10.0927 - val_accuracy: 0.3806\n",
      "Epoch 320/500\n",
      " - 1s - loss: 1.1275 - accuracy: 0.5255 - val_loss: 10.2294 - val_accuracy: 0.3950\n",
      "Epoch 321/500\n",
      " - 1s - loss: 1.0842 - accuracy: 0.5419 - val_loss: 10.8741 - val_accuracy: 0.4094\n",
      "Epoch 322/500\n",
      " - 1s - loss: 1.0912 - accuracy: 0.5306 - val_loss: 10.5689 - val_accuracy: 0.3465\n",
      "Epoch 323/500\n",
      " - 1s - loss: 1.2215 - accuracy: 0.4972 - val_loss: 10.2783 - val_accuracy: 0.3701\n",
      "Epoch 324/500\n",
      " - 1s - loss: 1.2111 - accuracy: 0.5034 - val_loss: 9.9843 - val_accuracy: 0.4252\n",
      "Epoch 325/500\n",
      " - 0s - loss: 1.1204 - accuracy: 0.5266 - val_loss: 10.3811 - val_accuracy: 0.3871\n",
      "Epoch 326/500\n",
      " - 0s - loss: 1.0825 - accuracy: 0.5365 - val_loss: 10.4680 - val_accuracy: 0.3701\n",
      "Epoch 327/500\n",
      " - 0s - loss: 1.0745 - accuracy: 0.5473 - val_loss: 10.4036 - val_accuracy: 0.4160\n",
      "Epoch 328/500\n",
      " - 0s - loss: 1.1108 - accuracy: 0.5355 - val_loss: 10.5051 - val_accuracy: 0.3924\n",
      "Epoch 329/500\n",
      " - 0s - loss: 1.1206 - accuracy: 0.5245 - val_loss: 10.5188 - val_accuracy: 0.4029\n",
      "Epoch 330/500\n",
      " - 1s - loss: 1.0910 - accuracy: 0.5479 - val_loss: 10.6780 - val_accuracy: 0.4042\n",
      "Epoch 331/500\n",
      " - 1s - loss: 1.0541 - accuracy: 0.5458 - val_loss: 10.6839 - val_accuracy: 0.3898\n",
      "Epoch 332/500\n",
      " - 0s - loss: 1.4883 - accuracy: 0.4733 - val_loss: 9.4589 - val_accuracy: 0.3898\n",
      "Epoch 333/500\n",
      " - 1s - loss: 1.2147 - accuracy: 0.5076 - val_loss: 9.4573 - val_accuracy: 0.3806\n",
      "Epoch 334/500\n",
      " - 0s - loss: 1.1017 - accuracy: 0.5375 - val_loss: 9.6739 - val_accuracy: 0.3832\n",
      "Epoch 335/500\n",
      " - 0s - loss: 1.0833 - accuracy: 0.5448 - val_loss: 9.8687 - val_accuracy: 0.4094\n",
      "Epoch 336/500\n",
      " - 0s - loss: 1.0720 - accuracy: 0.5400 - val_loss: 10.0535 - val_accuracy: 0.3898\n",
      "Epoch 337/500\n",
      " - 1s - loss: 1.1054 - accuracy: 0.5324 - val_loss: 10.0521 - val_accuracy: 0.4055\n",
      "Epoch 338/500\n",
      " - 1s - loss: 1.0711 - accuracy: 0.5466 - val_loss: 9.9722 - val_accuracy: 0.3963\n",
      "Epoch 339/500\n",
      " - 1s - loss: 1.0631 - accuracy: 0.5451 - val_loss: 10.4512 - val_accuracy: 0.3793\n",
      "Epoch 340/500\n",
      " - 1s - loss: 1.0438 - accuracy: 0.5512 - val_loss: 10.3606 - val_accuracy: 0.4134\n",
      "Epoch 341/500\n",
      " - 1s - loss: 1.0477 - accuracy: 0.5466 - val_loss: 10.5420 - val_accuracy: 0.4108\n",
      "Epoch 342/500\n",
      " - 1s - loss: 1.0799 - accuracy: 0.5321 - val_loss: 11.1757 - val_accuracy: 0.3845\n",
      "Epoch 343/500\n",
      " - 1s - loss: 1.0784 - accuracy: 0.5480 - val_loss: 10.7141 - val_accuracy: 0.3543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 344/500\n",
      " - 0s - loss: 1.1132 - accuracy: 0.5290 - val_loss: 11.0634 - val_accuracy: 0.4016\n",
      "Epoch 345/500\n",
      " - 0s - loss: 1.0597 - accuracy: 0.5550 - val_loss: 10.4474 - val_accuracy: 0.3740\n",
      "Epoch 346/500\n",
      " - 0s - loss: 1.0591 - accuracy: 0.5506 - val_loss: 10.8521 - val_accuracy: 0.3950\n",
      "Epoch 347/500\n",
      " - 0s - loss: 1.0676 - accuracy: 0.5436 - val_loss: 11.1695 - val_accuracy: 0.4042\n",
      "Epoch 348/500\n",
      " - 0s - loss: 1.0884 - accuracy: 0.5358 - val_loss: 10.8895 - val_accuracy: 0.3793\n",
      "Epoch 349/500\n",
      " - 1s - loss: 1.1593 - accuracy: 0.5306 - val_loss: 10.8042 - val_accuracy: 0.3924\n",
      "Epoch 350/500\n",
      " - 0s - loss: 1.0732 - accuracy: 0.5450 - val_loss: 10.2004 - val_accuracy: 0.4003\n",
      "Epoch 351/500\n",
      " - 1s - loss: 1.0547 - accuracy: 0.5425 - val_loss: 10.6218 - val_accuracy: 0.4081\n",
      "Epoch 352/500\n",
      " - 1s - loss: 1.0540 - accuracy: 0.5414 - val_loss: 11.0869 - val_accuracy: 0.3714\n",
      "Epoch 353/500\n",
      " - 1s - loss: 1.0433 - accuracy: 0.5474 - val_loss: 10.0424 - val_accuracy: 0.4094\n",
      "Epoch 354/500\n",
      " - 1s - loss: 1.1098 - accuracy: 0.5320 - val_loss: 11.1202 - val_accuracy: 0.3924\n",
      "Epoch 355/500\n",
      " - 1s - loss: 1.0855 - accuracy: 0.5269 - val_loss: 10.4527 - val_accuracy: 0.4055\n",
      "Epoch 356/500\n",
      " - 1s - loss: 1.1007 - accuracy: 0.5274 - val_loss: 10.8161 - val_accuracy: 0.4173\n",
      "Epoch 357/500\n",
      " - 1s - loss: 1.0379 - accuracy: 0.5563 - val_loss: 10.6765 - val_accuracy: 0.4029\n",
      "Epoch 358/500\n",
      " - 1s - loss: 1.1081 - accuracy: 0.5398 - val_loss: 10.5334 - val_accuracy: 0.4055\n",
      "Epoch 359/500\n",
      " - 1s - loss: 1.0449 - accuracy: 0.5540 - val_loss: 10.7612 - val_accuracy: 0.4029\n",
      "Epoch 360/500\n",
      " - 1s - loss: 1.0389 - accuracy: 0.5461 - val_loss: 11.3350 - val_accuracy: 0.3832\n",
      "Epoch 361/500\n",
      " - 0s - loss: 1.0508 - accuracy: 0.5474 - val_loss: 11.5787 - val_accuracy: 0.3688\n",
      "Epoch 362/500\n",
      " - 0s - loss: 1.0277 - accuracy: 0.5504 - val_loss: 11.2189 - val_accuracy: 0.3937\n",
      "Epoch 363/500\n",
      " - 0s - loss: 1.0682 - accuracy: 0.5482 - val_loss: 11.0691 - val_accuracy: 0.4213\n",
      "Epoch 364/500\n",
      " - 0s - loss: 1.0513 - accuracy: 0.5530 - val_loss: 11.0607 - val_accuracy: 0.4029\n",
      "Epoch 365/500\n",
      " - 0s - loss: 1.2164 - accuracy: 0.5096 - val_loss: 10.7820 - val_accuracy: 0.3911\n",
      "Epoch 366/500\n",
      " - 0s - loss: 1.0816 - accuracy: 0.5400 - val_loss: 11.1062 - val_accuracy: 0.4068\n",
      "Epoch 367/500\n",
      " - 0s - loss: 1.0753 - accuracy: 0.5467 - val_loss: 10.4574 - val_accuracy: 0.3635\n",
      "Epoch 368/500\n",
      " - 0s - loss: 1.0624 - accuracy: 0.5435 - val_loss: 10.9080 - val_accuracy: 0.4081\n",
      "Epoch 369/500\n",
      " - 0s - loss: 1.0556 - accuracy: 0.5512 - val_loss: 11.2650 - val_accuracy: 0.4121\n",
      "Epoch 370/500\n",
      " - 0s - loss: 1.0567 - accuracy: 0.5452 - val_loss: 11.2369 - val_accuracy: 0.4042\n",
      "Epoch 371/500\n",
      " - 0s - loss: 1.1200 - accuracy: 0.5474 - val_loss: 10.4464 - val_accuracy: 0.3871\n",
      "Epoch 372/500\n",
      " - 0s - loss: 1.0309 - accuracy: 0.5520 - val_loss: 10.4930 - val_accuracy: 0.4055\n",
      "Epoch 373/500\n",
      " - 1s - loss: 1.2502 - accuracy: 0.4953 - val_loss: 10.4076 - val_accuracy: 0.4003\n",
      "Epoch 374/500\n",
      " - 1s - loss: 1.1084 - accuracy: 0.5455 - val_loss: 10.6061 - val_accuracy: 0.4042\n",
      "Epoch 375/500\n",
      " - 1s - loss: 1.0438 - accuracy: 0.5552 - val_loss: 10.5410 - val_accuracy: 0.4029\n",
      "Epoch 376/500\n",
      " - 1s - loss: 0.9983 - accuracy: 0.5660 - val_loss: 10.8408 - val_accuracy: 0.3701\n",
      "Epoch 377/500\n",
      " - 1s - loss: 1.0695 - accuracy: 0.5539 - val_loss: 10.7988 - val_accuracy: 0.4186\n",
      "Epoch 378/500\n",
      " - 1s - loss: 1.0688 - accuracy: 0.5390 - val_loss: 11.0806 - val_accuracy: 0.3648\n",
      "Epoch 379/500\n",
      " - 1s - loss: 1.1897 - accuracy: 0.5178 - val_loss: 10.8582 - val_accuracy: 0.3780\n",
      "Epoch 380/500\n",
      " - 1s - loss: 1.0113 - accuracy: 0.5665 - val_loss: 11.4511 - val_accuracy: 0.3740\n",
      "Epoch 381/500\n",
      " - 1s - loss: 1.0393 - accuracy: 0.5541 - val_loss: 10.7675 - val_accuracy: 0.3793\n",
      "Epoch 382/500\n",
      " - 1s - loss: 0.9834 - accuracy: 0.5626 - val_loss: 11.1576 - val_accuracy: 0.4121\n",
      "Epoch 383/500\n",
      " - 1s - loss: 0.9788 - accuracy: 0.5644 - val_loss: 10.7836 - val_accuracy: 0.4331\n",
      "Epoch 384/500\n",
      " - 1s - loss: 0.9947 - accuracy: 0.5620 - val_loss: 11.7017 - val_accuracy: 0.4134\n",
      "Epoch 385/500\n",
      " - 1s - loss: 0.9912 - accuracy: 0.5613 - val_loss: 11.6113 - val_accuracy: 0.4042\n",
      "Epoch 386/500\n",
      " - 1s - loss: 1.0422 - accuracy: 0.5498 - val_loss: 11.1680 - val_accuracy: 0.4003\n",
      "Epoch 387/500\n",
      " - 0s - loss: 1.0966 - accuracy: 0.5471 - val_loss: 11.0101 - val_accuracy: 0.3701\n",
      "Epoch 388/500\n",
      " - 0s - loss: 1.1615 - accuracy: 0.5226 - val_loss: 12.1351 - val_accuracy: 0.4003\n",
      "Epoch 389/500\n",
      " - 0s - loss: 1.0857 - accuracy: 0.5452 - val_loss: 10.7997 - val_accuracy: 0.3858\n",
      "Epoch 390/500\n",
      " - 0s - loss: 1.0093 - accuracy: 0.5553 - val_loss: 11.1878 - val_accuracy: 0.3898\n",
      "Epoch 391/500\n",
      " - 0s - loss: 1.0099 - accuracy: 0.5543 - val_loss: 10.8210 - val_accuracy: 0.3845\n",
      "Epoch 392/500\n",
      " - 0s - loss: 1.4836 - accuracy: 0.4866 - val_loss: 9.7431 - val_accuracy: 0.3911\n",
      "Epoch 393/500\n",
      " - 0s - loss: 1.1364 - accuracy: 0.5552 - val_loss: 9.5161 - val_accuracy: 0.4370\n",
      "Epoch 394/500\n",
      " - 0s - loss: 1.0652 - accuracy: 0.5556 - val_loss: 10.3473 - val_accuracy: 0.4055\n",
      "Epoch 395/500\n",
      " - 0s - loss: 1.1128 - accuracy: 0.5295 - val_loss: 10.2449 - val_accuracy: 0.3793\n",
      "Epoch 396/500\n",
      " - 0s - loss: 1.0025 - accuracy: 0.5601 - val_loss: 10.7152 - val_accuracy: 0.3898\n",
      "Epoch 397/500\n",
      " - 0s - loss: 1.0363 - accuracy: 0.5572 - val_loss: 12.0723 - val_accuracy: 0.4003\n",
      "Epoch 398/500\n",
      " - 0s - loss: 1.2121 - accuracy: 0.5522 - val_loss: 9.6443 - val_accuracy: 0.4081\n",
      "Epoch 399/500\n",
      " - 0s - loss: 1.0209 - accuracy: 0.5585 - val_loss: 10.1849 - val_accuracy: 0.3990\n",
      "Epoch 400/500\n",
      " - 0s - loss: 1.0013 - accuracy: 0.5628 - val_loss: 10.6986 - val_accuracy: 0.4068\n",
      "Epoch 401/500\n",
      " - 0s - loss: 1.0019 - accuracy: 0.5533 - val_loss: 10.5726 - val_accuracy: 0.3911\n",
      "Epoch 402/500\n",
      " - 0s - loss: 1.0020 - accuracy: 0.5555 - val_loss: 10.2920 - val_accuracy: 0.4134\n",
      "Epoch 403/500\n",
      " - 1s - loss: 0.9814 - accuracy: 0.5753 - val_loss: 11.0177 - val_accuracy: 0.3963\n",
      "Epoch 404/500\n",
      " - 0s - loss: 0.9588 - accuracy: 0.5728 - val_loss: 11.2680 - val_accuracy: 0.3963\n",
      "Epoch 405/500\n",
      " - 0s - loss: 0.9975 - accuracy: 0.5728 - val_loss: 11.2358 - val_accuracy: 0.4055\n",
      "Epoch 406/500\n",
      " - 1s - loss: 0.9861 - accuracy: 0.5725 - val_loss: 11.0275 - val_accuracy: 0.4042\n",
      "Epoch 407/500\n",
      " - 1s - loss: 1.0144 - accuracy: 0.5609 - val_loss: 11.7747 - val_accuracy: 0.4016\n",
      "Epoch 408/500\n",
      " - 1s - loss: 1.0241 - accuracy: 0.5556 - val_loss: 10.6179 - val_accuracy: 0.4199\n",
      "Epoch 409/500\n",
      " - 1s - loss: 0.9993 - accuracy: 0.5625 - val_loss: 11.0908 - val_accuracy: 0.4160\n",
      "Epoch 410/500\n",
      " - 0s - loss: 1.0369 - accuracy: 0.5489 - val_loss: 11.7584 - val_accuracy: 0.4160\n",
      "Epoch 411/500\n",
      " - 0s - loss: 0.9471 - accuracy: 0.5909 - val_loss: 10.9847 - val_accuracy: 0.3845\n",
      "Epoch 412/500\n",
      " - 0s - loss: 0.9960 - accuracy: 0.5641 - val_loss: 11.9131 - val_accuracy: 0.3845\n",
      "Epoch 413/500\n",
      " - 0s - loss: 1.0258 - accuracy: 0.5520 - val_loss: 11.5167 - val_accuracy: 0.3780\n",
      "Epoch 414/500\n",
      " - 0s - loss: 1.0723 - accuracy: 0.5425 - val_loss: 11.7239 - val_accuracy: 0.3753\n",
      "Epoch 415/500\n",
      " - 0s - loss: 1.0152 - accuracy: 0.5614 - val_loss: 11.2051 - val_accuracy: 0.3937\n",
      "Epoch 416/500\n",
      " - 0s - loss: 1.0653 - accuracy: 0.5543 - val_loss: 11.5494 - val_accuracy: 0.3845\n",
      "Epoch 417/500\n",
      " - 0s - loss: 1.0982 - accuracy: 0.5486 - val_loss: 11.1447 - val_accuracy: 0.3858\n",
      "Epoch 418/500\n",
      " - 0s - loss: 1.0869 - accuracy: 0.5396 - val_loss: 11.4564 - val_accuracy: 0.4094\n",
      "Epoch 419/500\n",
      " - 0s - loss: 1.0841 - accuracy: 0.5517 - val_loss: 11.1461 - val_accuracy: 0.3793\n",
      "Epoch 420/500\n",
      " - 0s - loss: 0.9831 - accuracy: 0.5649 - val_loss: 11.5446 - val_accuracy: 0.3950\n",
      "Epoch 421/500\n",
      " - 0s - loss: 0.9738 - accuracy: 0.5682 - val_loss: 11.1760 - val_accuracy: 0.3990\n",
      "Epoch 422/500\n",
      " - 0s - loss: 1.0076 - accuracy: 0.5670 - val_loss: 11.5743 - val_accuracy: 0.4160\n",
      "Epoch 423/500\n",
      " - 0s - loss: 0.9695 - accuracy: 0.5749 - val_loss: 11.5695 - val_accuracy: 0.3845\n",
      "Epoch 424/500\n",
      " - 0s - loss: 1.0988 - accuracy: 0.5452 - val_loss: 10.7662 - val_accuracy: 0.3858\n",
      "Epoch 425/500\n",
      " - 0s - loss: 1.1595 - accuracy: 0.5285 - val_loss: 10.8042 - val_accuracy: 0.3885\n",
      "Epoch 426/500\n",
      " - 1s - loss: 0.9657 - accuracy: 0.5699 - val_loss: 11.8473 - val_accuracy: 0.3688\n",
      "Epoch 427/500\n",
      " - 0s - loss: 0.9709 - accuracy: 0.5690 - val_loss: 11.3465 - val_accuracy: 0.4160\n",
      "Epoch 428/500\n",
      " - 1s - loss: 1.0355 - accuracy: 0.5483 - val_loss: 10.8155 - val_accuracy: 0.3793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 429/500\n",
      " - 1s - loss: 1.0468 - accuracy: 0.5617 - val_loss: 11.4739 - val_accuracy: 0.3911\n",
      "Epoch 430/500\n",
      " - 1s - loss: 1.0306 - accuracy: 0.5610 - val_loss: 11.6023 - val_accuracy: 0.3622\n",
      "Epoch 431/500\n",
      " - 1s - loss: 0.9914 - accuracy: 0.5779 - val_loss: 11.2726 - val_accuracy: 0.3950\n",
      "Epoch 432/500\n",
      " - 1s - loss: 0.9725 - accuracy: 0.5684 - val_loss: 11.6706 - val_accuracy: 0.3911\n",
      "Epoch 433/500\n",
      " - 0s - loss: 0.9857 - accuracy: 0.5654 - val_loss: 11.2165 - val_accuracy: 0.4134\n",
      "Epoch 434/500\n",
      " - 0s - loss: 0.9319 - accuracy: 0.5766 - val_loss: 11.4454 - val_accuracy: 0.4029\n",
      "Epoch 435/500\n",
      " - 0s - loss: 0.9578 - accuracy: 0.5695 - val_loss: 11.8096 - val_accuracy: 0.4147\n",
      "Epoch 436/500\n",
      " - 0s - loss: 1.0116 - accuracy: 0.5714 - val_loss: 11.2732 - val_accuracy: 0.3596\n",
      "Epoch 437/500\n",
      " - 0s - loss: 0.9621 - accuracy: 0.5679 - val_loss: 11.4922 - val_accuracy: 0.4081\n",
      "Epoch 438/500\n",
      " - 0s - loss: 0.9504 - accuracy: 0.5741 - val_loss: 11.7692 - val_accuracy: 0.3845\n",
      "Epoch 439/500\n",
      " - 0s - loss: 0.9797 - accuracy: 0.5651 - val_loss: 11.6028 - val_accuracy: 0.3990\n",
      "Epoch 440/500\n",
      " - 0s - loss: 0.9696 - accuracy: 0.5721 - val_loss: 11.7138 - val_accuracy: 0.3963\n",
      "Epoch 441/500\n",
      " - 0s - loss: 0.9592 - accuracy: 0.5730 - val_loss: 11.8671 - val_accuracy: 0.4042\n",
      "Epoch 442/500\n",
      " - 0s - loss: 0.9959 - accuracy: 0.5613 - val_loss: 11.3946 - val_accuracy: 0.4068\n",
      "Epoch 443/500\n",
      " - 0s - loss: 0.9874 - accuracy: 0.5698 - val_loss: 11.8308 - val_accuracy: 0.3793\n",
      "Epoch 444/500\n",
      " - 0s - loss: 0.9640 - accuracy: 0.5749 - val_loss: 11.5499 - val_accuracy: 0.4186\n",
      "Epoch 445/500\n",
      " - 0s - loss: 1.0217 - accuracy: 0.5473 - val_loss: 11.5562 - val_accuracy: 0.4081\n",
      "Epoch 446/500\n",
      " - 0s - loss: 0.9356 - accuracy: 0.5826 - val_loss: 11.7520 - val_accuracy: 0.3924\n",
      "Epoch 447/500\n",
      " - 0s - loss: 0.9612 - accuracy: 0.5822 - val_loss: 11.4321 - val_accuracy: 0.4029\n",
      "Epoch 448/500\n",
      " - 0s - loss: 0.9768 - accuracy: 0.5587 - val_loss: 11.1474 - val_accuracy: 0.3885\n",
      "Epoch 449/500\n",
      " - 1s - loss: 1.0088 - accuracy: 0.5517 - val_loss: 12.4259 - val_accuracy: 0.3990\n",
      "Epoch 450/500\n",
      " - 1s - loss: 1.0180 - accuracy: 0.5682 - val_loss: 11.6501 - val_accuracy: 0.4134\n",
      "Epoch 451/500\n",
      " - 1s - loss: 0.9913 - accuracy: 0.5632 - val_loss: 11.4875 - val_accuracy: 0.4003\n",
      "Epoch 452/500\n",
      " - 1s - loss: 0.9764 - accuracy: 0.5654 - val_loss: 11.7283 - val_accuracy: 0.4003\n",
      "Epoch 453/500\n",
      " - 1s - loss: 1.0071 - accuracy: 0.5614 - val_loss: 11.4935 - val_accuracy: 0.3911\n",
      "Epoch 454/500\n",
      " - 1s - loss: 1.0019 - accuracy: 0.5721 - val_loss: 11.3505 - val_accuracy: 0.4213\n",
      "Epoch 455/500\n",
      " - 1s - loss: 1.1204 - accuracy: 0.5397 - val_loss: 10.6595 - val_accuracy: 0.3832\n",
      "Epoch 456/500\n",
      " - 1s - loss: 1.0867 - accuracy: 0.5558 - val_loss: 10.2291 - val_accuracy: 0.4068\n",
      "Epoch 457/500\n",
      " - 1s - loss: 0.9320 - accuracy: 0.5787 - val_loss: 10.6300 - val_accuracy: 0.3885\n",
      "Epoch 458/500\n",
      " - 0s - loss: 0.9318 - accuracy: 0.5809 - val_loss: 10.9637 - val_accuracy: 0.3976\n",
      "Epoch 459/500\n",
      " - 0s - loss: 0.9262 - accuracy: 0.5798 - val_loss: 11.0527 - val_accuracy: 0.4252\n",
      "Epoch 460/500\n",
      " - 0s - loss: 0.9433 - accuracy: 0.5728 - val_loss: 11.2904 - val_accuracy: 0.3963\n",
      "Epoch 461/500\n",
      " - 0s - loss: 0.9527 - accuracy: 0.5746 - val_loss: 11.4137 - val_accuracy: 0.4252\n",
      "Epoch 462/500\n",
      " - 0s - loss: 0.9395 - accuracy: 0.5635 - val_loss: 12.0138 - val_accuracy: 0.3898\n",
      "Epoch 463/500\n",
      " - 0s - loss: 0.9321 - accuracy: 0.5693 - val_loss: 11.4559 - val_accuracy: 0.4252\n",
      "Epoch 464/500\n",
      " - 0s - loss: 0.9235 - accuracy: 0.5794 - val_loss: 12.1059 - val_accuracy: 0.3950\n",
      "Epoch 465/500\n",
      " - 0s - loss: 0.9373 - accuracy: 0.5800 - val_loss: 11.6271 - val_accuracy: 0.3911\n",
      "Epoch 466/500\n",
      " - 0s - loss: 0.9632 - accuracy: 0.5741 - val_loss: 11.8555 - val_accuracy: 0.4016\n",
      "Epoch 467/500\n",
      " - 0s - loss: 1.0695 - accuracy: 0.5444 - val_loss: 11.7399 - val_accuracy: 0.4291\n",
      "Epoch 468/500\n",
      " - 0s - loss: 0.9939 - accuracy: 0.5801 - val_loss: 11.4551 - val_accuracy: 0.3911\n",
      "Epoch 469/500\n",
      " - 0s - loss: 0.9997 - accuracy: 0.5582 - val_loss: 11.4009 - val_accuracy: 0.3885\n",
      "Epoch 470/500\n",
      " - 0s - loss: 0.9573 - accuracy: 0.5647 - val_loss: 11.3679 - val_accuracy: 0.3898\n",
      "Epoch 471/500\n",
      " - 0s - loss: 1.0031 - accuracy: 0.5668 - val_loss: 11.4672 - val_accuracy: 0.3491\n",
      "Epoch 472/500\n",
      " - 0s - loss: 1.3796 - accuracy: 0.5178 - val_loss: 10.0476 - val_accuracy: 0.3885\n",
      "Epoch 473/500\n",
      " - 0s - loss: 1.0079 - accuracy: 0.5515 - val_loss: 10.3120 - val_accuracy: 0.4199\n",
      "Epoch 474/500\n",
      " - 0s - loss: 0.9250 - accuracy: 0.5752 - val_loss: 10.5877 - val_accuracy: 0.4239\n",
      "Epoch 475/500\n",
      " - 0s - loss: 0.8921 - accuracy: 0.5906 - val_loss: 10.7404 - val_accuracy: 0.4042\n",
      "Epoch 476/500\n",
      " - 0s - loss: 0.9234 - accuracy: 0.5737 - val_loss: 11.0503 - val_accuracy: 0.3845\n",
      "Epoch 477/500\n",
      " - 0s - loss: 0.9397 - accuracy: 0.5762 - val_loss: 11.0441 - val_accuracy: 0.4108\n",
      "Epoch 478/500\n",
      " - 1s - loss: 0.8956 - accuracy: 0.5976 - val_loss: 11.3612 - val_accuracy: 0.3924\n",
      "Epoch 479/500\n",
      " - 1s - loss: 0.9144 - accuracy: 0.5858 - val_loss: 11.2406 - val_accuracy: 0.4278\n",
      "Epoch 480/500\n",
      " - 1s - loss: 0.9409 - accuracy: 0.5771 - val_loss: 11.4535 - val_accuracy: 0.4055\n",
      "Epoch 481/500\n",
      " - 1s - loss: 0.9186 - accuracy: 0.5886 - val_loss: 11.4747 - val_accuracy: 0.3832\n",
      "Epoch 482/500\n",
      " - 1s - loss: 0.9914 - accuracy: 0.5521 - val_loss: 11.0416 - val_accuracy: 0.4186\n",
      "Epoch 483/500\n",
      " - 1s - loss: 0.9705 - accuracy: 0.5651 - val_loss: 11.6493 - val_accuracy: 0.4226\n",
      "Epoch 484/500\n",
      " - 1s - loss: 0.9507 - accuracy: 0.5718 - val_loss: 11.5584 - val_accuracy: 0.4081\n",
      "Epoch 485/500\n",
      " - 0s - loss: 1.0499 - accuracy: 0.5630 - val_loss: 10.7569 - val_accuracy: 0.3806\n",
      "Epoch 486/500\n",
      " - 0s - loss: 1.1218 - accuracy: 0.5581 - val_loss: 10.8396 - val_accuracy: 0.4003\n",
      "Epoch 487/500\n",
      " - 0s - loss: 0.9602 - accuracy: 0.5795 - val_loss: 10.9679 - val_accuracy: 0.4042\n",
      "Epoch 488/500\n",
      " - 0s - loss: 0.9232 - accuracy: 0.5747 - val_loss: 11.4979 - val_accuracy: 0.4147\n",
      "Epoch 489/500\n",
      " - 0s - loss: 0.9058 - accuracy: 0.5871 - val_loss: 11.4029 - val_accuracy: 0.4239\n",
      "Epoch 490/500\n",
      " - 0s - loss: 0.8839 - accuracy: 0.6014 - val_loss: 11.5484 - val_accuracy: 0.4029\n",
      "Epoch 491/500\n",
      " - 0s - loss: 0.8833 - accuracy: 0.5881 - val_loss: 11.8428 - val_accuracy: 0.4186\n",
      "Epoch 492/500\n",
      " - 0s - loss: 0.9321 - accuracy: 0.5699 - val_loss: 11.2840 - val_accuracy: 0.4016\n",
      "Epoch 493/500\n",
      " - 0s - loss: 0.9011 - accuracy: 0.5816 - val_loss: 11.9313 - val_accuracy: 0.3819\n",
      "Epoch 494/500\n",
      " - 0s - loss: 0.9797 - accuracy: 0.5572 - val_loss: 11.6004 - val_accuracy: 0.4436\n",
      "Epoch 495/500\n",
      " - 0s - loss: 1.1248 - accuracy: 0.5356 - val_loss: 11.3286 - val_accuracy: 0.3871\n",
      "Epoch 496/500\n",
      " - 0s - loss: 1.1805 - accuracy: 0.5464 - val_loss: 10.4266 - val_accuracy: 0.3740\n",
      "Epoch 497/500\n",
      " - 0s - loss: 1.4598 - accuracy: 0.5191 - val_loss: 8.9419 - val_accuracy: 0.3911\n",
      "Epoch 498/500\n",
      " - 1s - loss: 1.1002 - accuracy: 0.5633 - val_loss: 9.1492 - val_accuracy: 0.4068\n",
      "Epoch 499/500\n",
      " - 1s - loss: 0.9936 - accuracy: 0.5794 - val_loss: 10.0433 - val_accuracy: 0.4016\n",
      "Epoch 500/500\n",
      " - 1s - loss: 1.0410 - accuracy: 0.5702 - val_loss: 9.5812 - val_accuracy: 0.4160\n"
     ]
    }
   ],
   "source": [
    "model_list_var1 = list()\n",
    "df_train1 = df_train.copy()\n",
    "# print(df_train1.head(1))\n",
    "df_train1[\"class\"] = df_train1[\"class\"] - 1\n",
    "dummy_y = np_utils.to_categorical(df_train1[\"class\"])\n",
    "n = dummy_y.shape[1]\n",
    "print(n)\n",
    "N = len(df_train1)\n",
    "print(N)\n",
    "s = np.vstack((df_train1[\"x\"],df_train1[\"y\"])).T\n",
    "\n",
    "num_basis = [5**2,7**2,11**2]\n",
    "knots_1d = [np.linspace(0,1,int(np.sqrt(i))) for i in num_basis]\n",
    "##Wendland kernel\n",
    "K = 0\n",
    "phi = np.zeros((N, sum(num_basis)))\n",
    "\n",
    "for res in range(len(num_basis)):\n",
    "    theta = 1/np.sqrt(num_basis[res])*2.5\n",
    "    knots_s1, knots_s2 = np.meshgrid(knots_1d[res],knots_1d[res])\n",
    "    knots = np.column_stack((knots_s1.flatten(),knots_s2.flatten()))\n",
    "    for i in range(num_basis[res]):\n",
    "        d = np.linalg.norm(s-knots[i,:],axis=1)/theta\n",
    "        for j in range(len(d)):\n",
    "            if d[j] >= 0 and d[j] <= 1:\n",
    "                phi[j,i + K] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "            else:\n",
    "                phi[j,i + K] = 0\n",
    "    K = K + num_basis[res]\n",
    "def model_function():\n",
    "    class_weights = class_weight.compute_class_weight('balanced',np.unique(df_train[\"class\"]),\n",
    "                                             df_train[\"class\"])\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    # DeepKriging model for continuous data\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(100, input_dim = 2,  kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(100, input_dim = phi.shape[1],  \n",
    "            kernel_initializer='he_uniform', activation='relu'))\n",
    "    # model.add(Dropout(rate=0.5))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    #     model.add(Dense(100, activation='relu'))\n",
    "    # model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    #     model.add(Dense(50, activation='relu'))\n",
    "    #     model.add(Dense(50, activation='relu'))\n",
    "    #     model.add(Dense(10, activation='relu'))\n",
    "    #model.add(Dense(50, activation='relu'))\n",
    "    #model.add(Dropout(rate=0.5))\n",
    "    #     model.add(Dense(10, activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(n, activation='softmax'))\n",
    "    NB_START_EPOCHS = 50 \n",
    "    # NB_START_EPOCHS = 200  # Number of epochs we usually start to train with\n",
    "    BATCH_SIZE = 64  \n",
    "    fold_no = 1\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor='val_accuracy', patience=200),\n",
    "                 ModelCheckpoint(filepath='indicator_kriging.h5', \n",
    "                                 monitor='val_accuracy', save_best_only=True)]\n",
    "    print(\"running model for variable 1.\")\n",
    "    result = model.fit(phi, dummy_y, callbacks=callbacks, class_weight = class_weight_dict,\n",
    "               validation_split = 0.1, epochs = 500, batch_size = 128, verbose = 2)\n",
    "\n",
    "    model = keras.models.load_model('indicator_kriging.h5')\n",
    "    return model\n",
    "model_list_var1.append(model_function())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e96e98d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "N = len(df_loc)\n",
    "s = np.vstack((df_loc[\"x\"],df_loc[\"y\"])).T\n",
    "\n",
    "num_basis = [5**2,7**2,11**2]\n",
    "knots_1d = [np.linspace(0,1,int(np.sqrt(i))) for i in num_basis]\n",
    "##Wendland kernel\n",
    "K = 0\n",
    "phi = np.zeros((N, sum(num_basis)))\n",
    "\n",
    "for res in range(len(num_basis)):\n",
    "    theta = 1/np.sqrt(num_basis[res])*2.5\n",
    "    knots_s1, knots_s2 = np.meshgrid(knots_1d[res],knots_1d[res])\n",
    "    knots = np.column_stack((knots_s1.flatten(),knots_s2.flatten()))\n",
    "    for i in range(num_basis[res]):\n",
    "        d = np.linalg.norm(s-knots[i,:],axis=1)/theta\n",
    "        for j in range(len(d)):\n",
    "            if d[j] >= 0 and d[j] <= 1:\n",
    "                phi[j,i + K] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "            else:\n",
    "                phi[j,i + K] = 0\n",
    "    K = K + num_basis[res]\n",
    "model = model_list_var1[0]\n",
    "pred = model.predict(phi)\n",
    "pred_df = pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2d97834e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "      <th>138</th>\n",
       "      <th>139</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.739566e-19</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.324946</td>\n",
       "      <td>0.061119</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>4.717139e-10</td>\n",
       "      <td>1.525096e-15</td>\n",
       "      <td>1.553062e-26</td>\n",
       "      <td>1.268484e-38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.664692e-20</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.677809</td>\n",
       "      <td>0.192017</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>4.095351e-08</td>\n",
       "      <td>1.709391e-13</td>\n",
       "      <td>6.433325e-23</td>\n",
       "      <td>4.303630e-34</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.026823e-18</td>\n",
       "      <td>0.000452</td>\n",
       "      <td>0.680863</td>\n",
       "      <td>0.299867</td>\n",
       "      <td>0.001125</td>\n",
       "      <td>1.767172e-07</td>\n",
       "      <td>1.812267e-12</td>\n",
       "      <td>1.689698e-21</td>\n",
       "      <td>1.632681e-32</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.360958e-17</td>\n",
       "      <td>0.000624</td>\n",
       "      <td>0.410871</td>\n",
       "      <td>0.582680</td>\n",
       "      <td>0.005241</td>\n",
       "      <td>3.654676e-06</td>\n",
       "      <td>2.297093e-10</td>\n",
       "      <td>1.952453e-18</td>\n",
       "      <td>8.361681e-29</td>\n",
       "      <td>2.024800e-34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.020634e-14</td>\n",
       "      <td>0.000477</td>\n",
       "      <td>0.110420</td>\n",
       "      <td>0.861035</td>\n",
       "      <td>0.027893</td>\n",
       "      <td>1.640463e-04</td>\n",
       "      <td>1.390596e-07</td>\n",
       "      <td>3.388932e-14</td>\n",
       "      <td>1.699682e-23</td>\n",
       "      <td>1.642315e-27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8095</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>4.836693e-09</td>\n",
       "      <td>5.379264e-03</td>\n",
       "      <td>4.576569e-07</td>\n",
       "      <td>0.836334</td>\n",
       "      <td>0.120163</td>\n",
       "      <td>0.031579</td>\n",
       "      <td>8.460199e-12</td>\n",
       "      <td>4.232425e-22</td>\n",
       "      <td>2.840048e-25</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8096</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.685192e-34</td>\n",
       "      <td>1.758181e-11</td>\n",
       "      <td>7.126846e-12</td>\n",
       "      <td>0.011822</td>\n",
       "      <td>0.209085</td>\n",
       "      <td>0.764630</td>\n",
       "      <td>8.256384e-04</td>\n",
       "      <td>1.136447e-08</td>\n",
       "      <td>9.460909e-10</td>\n",
       "      <td>3.536104e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8097</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.605578e-30</td>\n",
       "      <td>5.830494e-10</td>\n",
       "      <td>4.743375e-11</td>\n",
       "      <td>0.038953</td>\n",
       "      <td>0.291365</td>\n",
       "      <td>0.662441</td>\n",
       "      <td>3.119585e-05</td>\n",
       "      <td>2.609468e-11</td>\n",
       "      <td>7.517369e-13</td>\n",
       "      <td>3.780268e-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8098</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188502e-20</td>\n",
       "      <td>4.146426e-07</td>\n",
       "      <td>2.318453e-11</td>\n",
       "      <td>0.484962</td>\n",
       "      <td>0.230948</td>\n",
       "      <td>0.186371</td>\n",
       "      <td>5.050597e-11</td>\n",
       "      <td>2.660673e-21</td>\n",
       "      <td>1.734875e-23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8099</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.016870e-12</td>\n",
       "      <td>6.314048e-08</td>\n",
       "      <td>6.228066e-18</td>\n",
       "      <td>0.006430</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>5.305738e-23</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8100 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0         1         2         3         4             5    \\\n",
       "0     1.739566e-19  0.003042  0.324946  0.061119  0.000007  4.717139e-10   \n",
       "1     9.664692e-20  0.000237  0.677809  0.192017  0.000538  4.095351e-08   \n",
       "2     1.026823e-18  0.000452  0.680863  0.299867  0.001125  1.767172e-07   \n",
       "3     5.360958e-17  0.000624  0.410871  0.582680  0.005241  3.654676e-06   \n",
       "4     1.020634e-14  0.000477  0.110420  0.861035  0.027893  1.640463e-04   \n",
       "...            ...       ...       ...       ...       ...           ...   \n",
       "8095  0.000000e+00  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
       "8096  0.000000e+00  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
       "8097  0.000000e+00  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
       "8098  0.000000e+00  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
       "8099  0.000000e+00  0.000000  0.000000  0.000000  0.000000  0.000000e+00   \n",
       "\n",
       "               6             7             8             9    ...  \\\n",
       "0     1.525096e-15  1.553062e-26  1.268484e-38  0.000000e+00  ...   \n",
       "1     1.709391e-13  6.433325e-23  4.303630e-34  0.000000e+00  ...   \n",
       "2     1.812267e-12  1.689698e-21  1.632681e-32  0.000000e+00  ...   \n",
       "3     2.297093e-10  1.952453e-18  8.361681e-29  2.024800e-34  ...   \n",
       "4     1.390596e-07  3.388932e-14  1.699682e-23  1.642315e-27  ...   \n",
       "...            ...           ...           ...           ...  ...   \n",
       "8095  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
       "8096  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
       "8097  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
       "8098  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
       "8099  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  ...   \n",
       "\n",
       "               130           131           132       133       134       135  \\\n",
       "0     0.000000e+00  0.000000e+00  0.000000e+00  0.000000  0.000000  0.000000   \n",
       "1     0.000000e+00  0.000000e+00  0.000000e+00  0.000000  0.000000  0.000000   \n",
       "2     0.000000e+00  0.000000e+00  0.000000e+00  0.000000  0.000000  0.000000   \n",
       "3     0.000000e+00  0.000000e+00  0.000000e+00  0.000000  0.000000  0.000000   \n",
       "4     0.000000e+00  0.000000e+00  0.000000e+00  0.000000  0.000000  0.000000   \n",
       "...            ...           ...           ...       ...       ...       ...   \n",
       "8095  4.836693e-09  5.379264e-03  4.576569e-07  0.836334  0.120163  0.031579   \n",
       "8096  1.685192e-34  1.758181e-11  7.126846e-12  0.011822  0.209085  0.764630   \n",
       "8097  1.605578e-30  5.830494e-10  4.743375e-11  0.038953  0.291365  0.662441   \n",
       "8098  2.188502e-20  4.146426e-07  2.318453e-11  0.484962  0.230948  0.186371   \n",
       "8099  1.016870e-12  6.314048e-08  6.228066e-18  0.006430  0.000085  0.000057   \n",
       "\n",
       "               136           137           138           139  \n",
       "0     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "1     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "2     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "3     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "4     0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "...            ...           ...           ...           ...  \n",
       "8095  8.460199e-12  4.232425e-22  2.840048e-25  0.000000e+00  \n",
       "8096  8.256384e-04  1.136447e-08  9.460909e-10  3.536104e-26  \n",
       "8097  3.119585e-05  2.609468e-11  7.517369e-13  3.780268e-31  \n",
       "8098  5.050597e-11  2.660673e-21  1.734875e-23  0.000000e+00  \n",
       "8099  5.305738e-23  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "\n",
       "[8100 rows x 140 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d73a2df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"projection_probs_deep.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35670cbe",
   "metadata": {},
   "source": [
    "### Modelling Variable 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0a0f01ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             x         y      var1      var2  proj_var1  proj_var2  threshold  \\\n",
      "4560  0.157303  0.988764 -5.350081 -5.250944  -5.306286  -5.300444          4   \n",
      "\n",
      "      dist_frm_orig  threshold2  threshold_var1  threshold_var2  \n",
      "4560      50.197071          10              15              16  \n",
      "40\n",
      "7290\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning:\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning:Pass classes=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39], y=4560    15\n",
      "1989    18\n",
      "2875    20\n",
      "509     26\n",
      "2565    25\n",
      "        ..\n",
      "1533    26\n",
      "6824    10\n",
      "7172    29\n",
      "4305    19\n",
      "4022    20\n",
      "Name: threshold_var1, Length: 7290, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model for variable 1.\n"
     ]
    }
   ],
   "source": [
    "model_list_var2 = list()\n",
    "df_train1 = df_train\n",
    "print(df_train1.head(1))\n",
    "df_train1[\"threshold_var2\"] = df_train1[\"threshold_var2\"] - 1\n",
    "dummy_y = np_utils.to_categorical(df_train1[\"threshold_var2\"])\n",
    "n = dummy_y.shape[1]\n",
    "print(n)\n",
    "N = len(df_train1)\n",
    "print(N)\n",
    "s = np.vstack((df_train1[\"x\"],df_train1[\"y\"])).T\n",
    "\n",
    "num_basis = [2**2,5**2,9**2]\n",
    "knots_1d = [np.linspace(0,1,int(np.sqrt(i))) for i in num_basis]\n",
    "##Wendland kernel\n",
    "K = 0\n",
    "phi = np.zeros((N, sum(num_basis)))\n",
    "\n",
    "for res in range(len(num_basis)):\n",
    "    theta = 1/np.sqrt(num_basis[res])*2.5\n",
    "    knots_s1, knots_s2 = np.meshgrid(knots_1d[res],knots_1d[res])\n",
    "    knots = np.column_stack((knots_s1.flatten(),knots_s2.flatten()))\n",
    "    for i in range(num_basis[res]):\n",
    "        d = np.linalg.norm(s-knots[i,:],axis=1)/theta\n",
    "        for j in range(len(d)):\n",
    "            if d[j] >= 0 and d[j] <= 1:\n",
    "                phi[j,i + K] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "            else:\n",
    "                phi[j,i + K] = 0\n",
    "    K = K + num_basis[res]\n",
    "def model_function():\n",
    "    class_weights = class_weight.compute_class_weight('balanced',np.unique(df_train1[\"threshold_var1\"]),\n",
    "                                             df_train1[\"threshold_var1\"])\n",
    "    class_weight_dict = dict(enumerate(class_weights))\n",
    "    # DeepKriging model for continuous data\n",
    "    model = Sequential()\n",
    "    # model.add(Dense(100, input_dim = 2,  kernel_initializer='he_uniform', activation='relu'))\n",
    "    model.add(Dense(100, input_dim = phi.shape[1],  \n",
    "            kernel_initializer='he_uniform', activation='relu'))\n",
    "    # model.add(Dropout(rate=0.5))\n",
    "    # model.add(BatchNormalization())\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    #     model.add(Dense(100, activation='relu'))\n",
    "    # model.add(Dense(100, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    #     model.add(Dense(50, activation='relu'))\n",
    "    #     model.add(Dense(50, activation='relu'))\n",
    "    #     model.add(Dense(10, activation='relu'))\n",
    "    #model.add(Dense(50, activation='relu'))\n",
    "    #model.add(Dropout(rate=0.5))\n",
    "    #     model.add(Dense(10, activation='relu'))\n",
    "    #model.add(BatchNormalization())\n",
    "    model.add(Dense(10, activation='relu'))\n",
    "    model.add(Dense(n, activation='softmax'))\n",
    "    NB_START_EPOCHS = 50 \n",
    "    # NB_START_EPOCHS = 200  # Number of epochs we usually start to train with\n",
    "    BATCH_SIZE = 64  \n",
    "    fold_no = 1\n",
    "    optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    callbacks = [EarlyStopping(monitor='val_accuracy', patience=200),\n",
    "                 ModelCheckpoint(filepath='indicator_kriging.h5', \n",
    "                                 monitor='val_accuracy', save_best_only=True)]\n",
    "    print(\"running model for variable 1.\")\n",
    "    result = model.fit(phi, dummy_y, callbacks=callbacks, class_weight = class_weight_dict,\n",
    "               validation_split = 0.1, epochs = 500, batch_size = 64, verbose = 0)\n",
    "\n",
    "    model = keras.models.load_model('indicator_kriging.h5')\n",
    "    return model\n",
    "model_list_var1.append(model_function())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ea84b681",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(df_test)\n",
    "s = np.vstack((df_test[\"x\"],df_test[\"y\"])).T\n",
    "\n",
    "num_basis = [2**2,5**2,9**2]\n",
    "knots_1d = [np.linspace(0,1,int(np.sqrt(i))) for i in num_basis]\n",
    "##Wendland kernel\n",
    "K = 0\n",
    "phi = np.zeros((N, sum(num_basis)))\n",
    "\n",
    "for res in range(len(num_basis)):\n",
    "    theta = 1/np.sqrt(num_basis[res])*2.5\n",
    "    knots_s1, knots_s2 = np.meshgrid(knots_1d[res],knots_1d[res])\n",
    "    knots = np.column_stack((knots_s1.flatten(),knots_s2.flatten()))\n",
    "    for i in range(num_basis[res]):\n",
    "        d = np.linalg.norm(s-knots[i,:],axis=1)/theta\n",
    "        for j in range(len(d)):\n",
    "            if d[j] >= 0 and d[j] <= 1:\n",
    "                phi[j,i + K] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "            else:\n",
    "                phi[j,i + K] = 0\n",
    "    K = K + num_basis[res]\n",
    "model = model_list_var1[1]\n",
    "pred = model.predict(phi)\n",
    "pred_df = pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5e6af5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"var2_probs.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff2ef71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3a159384",
   "metadata": {},
   "source": [
    "## Modelling the bivariate variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "719a265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11e13186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            x         y      var1      var2  proj_var1  proj_var2  threshold  \\\n",
      "509  0.910112  0.662921 -3.296573 -5.014667  -3.448834  -4.787949          1   \n",
      "\n",
      "     dist_frm_orig  threshold2  threshold_var1  threshold_var2  \n",
      "509      17.259161           4              26              16  \n",
      "20\n",
      "1167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning:Pass classes=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19], y=509      3\n",
      "27       2\n",
      "661      5\n",
      "1226    10\n",
      "969     15\n",
      "        ..\n",
      "512      6\n",
      "893      4\n",
      "648      3\n",
      "895      6\n",
      "93      11\n",
      "Name: threshold2, Length: 1167, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model for threshold 1.\n",
      "            x    y      var1      var2  proj_var1  proj_var2  threshold  \\\n",
      "1291  0.11236  0.0 -3.845167 -4.546533  -3.781946  -4.631694          2   \n",
      "\n",
      "      dist_frm_orig  threshold2  threshold_var1  threshold_var2  \n",
      "1291      22.185913           5              23              20  \n",
      "20\n",
      "1119\n",
      "running model for threshold 2.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning:Pass classes=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19], y=1291     4\n",
      "1292     3\n",
      "1293     3\n",
      "1294     3\n",
      "1295     4\n",
      "        ..\n",
      "2405    18\n",
      "2406    16\n",
      "2407    18\n",
      "2408     8\n",
      "2409     8\n",
      "Name: threshold2, Length: 1119, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             x         y      var1      var2  proj_var1  proj_var2  threshold  \\\n",
      "2875  0.752809  0.449438 -4.470393 -4.792529  -4.436628   -4.83253          3   \n",
      "\n",
      "      dist_frm_orig  threshold2  threshold_var1  threshold_var2  \n",
      "2875      33.708485           7              20              17  \n",
      "20\n",
      "993\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning:Pass classes=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19], y=2875     6\n",
      "2565     3\n",
      "2905    10\n",
      "2416     3\n",
      "3507    19\n",
      "        ..\n",
      "2770     2\n",
      "3498    18\n",
      "3050     8\n",
      "2910    12\n",
      "2911    12\n",
      "Name: threshold2, Length: 993, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model for threshold 3.\n",
      "             x         y      var1      var2  proj_var1  proj_var2  threshold  \\\n",
      "4560  0.157303  0.988764 -5.350081 -5.250944  -5.306286  -5.300444          4   \n",
      "\n",
      "      dist_frm_orig  threshold2  threshold_var1  threshold_var2  \n",
      "4560      50.197071          10              15              15  \n",
      "20\n",
      "968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning:Pass classes=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19], y=4560     9\n",
      "3571     3\n",
      "3642    11\n",
      "3877     4\n",
      "3874     2\n",
      "        ..\n",
      "3996     4\n",
      "3787     2\n",
      "4347     9\n",
      "4305     6\n",
      "4022     6\n",
      "Name: threshold2, Length: 968, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model for threshold 4.\n",
      "            x         y      var1      var2  proj_var1  proj_var2  threshold  \\\n",
      "4754  0.41573  0.101124 -3.470146 -3.132876  -3.405521  -3.200956          5   \n",
      "\n",
      "      dist_frm_orig  threshold2  threshold_var1  threshold_var2  \n",
      "4754      22.047682           4              25              26  \n",
      "20\n",
      "1027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning:Pass classes=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19], y=4754     3\n",
      "5401     8\n",
      "4631     4\n",
      "4750     6\n",
      "4748     7\n",
      "        ..\n",
      "5280     4\n",
      "5709    15\n",
      "4853    10\n",
      "4607     3\n",
      "5505     6\n",
      "Name: threshold2, Length: 1027, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model for threshold 5.\n",
      "             x         y      var1      var2  proj_var1  proj_var2  threshold  \\\n",
      "6523  0.044944  0.550562 -6.097978 -5.206317  -6.006661  -5.304751          6   \n",
      "\n",
      "      dist_frm_orig  threshold2  threshold_var1  threshold_var2  \n",
      "6523       67.13107          12              10              15  \n",
      "20\n",
      "1042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning:Pass classes=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19], y=6523    11\n",
      "6648     5\n",
      "5759    14\n",
      "5843     5\n",
      "6137     1\n",
      "        ..\n",
      "6109     1\n",
      "6401     1\n",
      "6573     3\n",
      "6835    12\n",
      "6824    11\n",
      "Name: threshold2, Length: 1042, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model for threshold 6.\n",
      "             x         y      var1      var2  proj_var1  proj_var2  threshold  \\\n",
      "7417  0.280899  0.393258 -3.156011 -2.183487  -3.121223  -2.227485          7   \n",
      "\n",
      "      dist_frm_orig  threshold2  threshold_var1  threshold_var2  \n",
      "7417      15.832108           3              27              31  \n",
      "20\n",
      "1093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning:\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:72: FutureWarning:Pass classes=[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19], y=7417     2\n",
      "7939     8\n",
      "6958     7\n",
      "7811     2\n",
      "7987    10\n",
      "        ..\n",
      "8004    14\n",
      "7911     9\n",
      "7161     7\n",
      "7475     4\n",
      "7172     2\n",
      "Name: threshold2, Length: 1093, dtype: int64 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running model for threshold 7.\n"
     ]
    }
   ],
   "source": [
    "for h in range(7):\n",
    "    df_train1 = df_train.loc[df_train['threshold'] == h+1]\n",
    "    if(len(np.unique(df_train1['threshold2'])) != 20):\n",
    "        df_train1 = df_loc.loc[df_loc['threshold'] == h+1]\n",
    "    else:\n",
    "        pass\n",
    "    print(df_train1.head(1))\n",
    "    df_train1[\"threshold2\"] = df_train1[\"threshold2\"] - 1\n",
    "    dummy_y = np_utils.to_categorical(df_train1[\"threshold2\"])\n",
    "    n = dummy_y.shape[1]\n",
    "    N = len(df_train1)\n",
    "    print(n)\n",
    "    print(N)\n",
    "    s = np.vstack((df_train1[\"x\"],df_train1[\"y\"])).T\n",
    "\n",
    "    num_basis = [2**2,5**2,9**2]\n",
    "    knots_1d = [np.linspace(0,1,int(np.sqrt(i))) for i in num_basis]\n",
    "    ##Wendland kernel\n",
    "    K = 0\n",
    "    phi = np.zeros((N, sum(num_basis)))\n",
    "\n",
    "    for res in range(len(num_basis)):\n",
    "        theta = 1/np.sqrt(num_basis[res])*2.5\n",
    "        knots_s1, knots_s2 = np.meshgrid(knots_1d[res],knots_1d[res])\n",
    "        knots = np.column_stack((knots_s1.flatten(),knots_s2.flatten()))\n",
    "        for i in range(num_basis[res]):\n",
    "            d = np.linalg.norm(s-knots[i,:],axis=1)/theta\n",
    "            for j in range(len(d)):\n",
    "                if d[j] >= 0 and d[j] <= 1:\n",
    "                    phi[j,i + K] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "                else:\n",
    "                    phi[j,i + K] = 0\n",
    "        K = K + num_basis[res]\n",
    "    def model_function():\n",
    "        class_weights = class_weight.compute_class_weight('balanced',np.unique(df_train1[\"threshold2\"]),\n",
    "                                                 df_train1[\"threshold2\"])\n",
    "        class_weight_dict = dict(enumerate(class_weights))\n",
    "        # DeepKriging model for continuous data\n",
    "        model = Sequential()\n",
    "        # model.add(Dense(100, input_dim = 2,  kernel_initializer='he_uniform', activation='relu'))\n",
    "        model.add(Dense(100, input_dim = phi.shape[1],  \n",
    "                kernel_initializer='he_uniform', activation='relu'))\n",
    "        # model.add(Dropout(rate=0.5))\n",
    "        # model.add(BatchNormalization())\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        #     model.add(Dense(100, activation='relu'))\n",
    "        # model.add(Dense(100, activation='relu'))\n",
    "        model.add(Dense(50, activation='relu'))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        #     model.add(Dense(50, activation='relu'))\n",
    "        #     model.add(Dense(50, activation='relu'))\n",
    "        #     model.add(Dense(10, activation='relu'))\n",
    "        #model.add(Dense(50, activation='relu'))\n",
    "        #model.add(Dropout(rate=0.5))\n",
    "        #     model.add(Dense(10, activation='relu'))\n",
    "        #model.add(BatchNormalization())\n",
    "        model.add(Dense(10, activation='relu'))\n",
    "        model.add(Dense(n, activation='softmax'))\n",
    "        NB_START_EPOCHS = 50 \n",
    "        # NB_START_EPOCHS = 200  # Number of epochs we usually start to train with\n",
    "        BATCH_SIZE = 64  \n",
    "        fold_no = 1\n",
    "        optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "        model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "        callbacks = [EarlyStopping(monitor='val_accuracy', patience=200),\n",
    "                     ModelCheckpoint(filepath='indicator_kriging.h5', \n",
    "                                     monitor='val_accuracy', save_best_only=True)]\n",
    "        print(\"running model for threshold \"+str(h+1)+\".\")\n",
    "        result = model.fit(phi, dummy_y, callbacks=callbacks, class_weight = class_weight_dict,\n",
    "                   validation_split = 0.1, epochs = 500, batch_size = 64, verbose = 0)\n",
    "\n",
    "        model = keras.models.load_model('indicator_kriging.h5')\n",
    "        return model\n",
    "    model_list.append(model_function())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0165717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             x         y      var1      var2  proj_var1  proj_var2  threshold  \\\n",
      "4560  0.157303  0.988764 -5.350081 -5.250944  -5.306286  -5.300444          4   \n",
      "\n",
      "      dist_frm_orig  threshold2  threshold_var1  threshold_var2  \n",
      "4560      50.197071          10              15              15  \n",
      "running model for mean. \n"
     ]
    }
   ],
   "source": [
    "N = len(df_test)\n",
    "s = np.vstack((df_test[\"x\"],df_test[\"y\"])).T\n",
    "\n",
    "num_basis = [2**2,5**2,9**2]\n",
    "knots_1d = [np.linspace(0,1,int(np.sqrt(i))) for i in num_basis]\n",
    "##Wendland kernel\n",
    "K = 0\n",
    "phi_test = np.zeros((N, sum(num_basis)))\n",
    "\n",
    "for res in range(len(num_basis)):\n",
    "    \n",
    "    theta = 1/np.sqrt(num_basis[res])*2.5\n",
    "    knots_s1, knots_s2 = np.meshgrid(knots_1d[res],knots_1d[res])\n",
    "    knots = np.column_stack((knots_s1.flatten(),knots_s2.flatten()))\n",
    "    for i in range(num_basis[res]):\n",
    "        d = np.linalg.norm(s-knots[i,:],axis=1)/theta\n",
    "        for j in range(len(d)):\n",
    "            if d[j] >= 0 and d[j] <= 1:\n",
    "                phi_test[j,i + K] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "            else:\n",
    "                phi_test[j,i + K] = 0\n",
    "    K = K + num_basis[res]\n",
    "y_test = np.array(df_test[[\"var1\",\"var2\"]])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(df_train.head(1))\n",
    "y = np.array(df_train[[\"var1\",\"var2\"]])\n",
    "N = len(df_train)\n",
    "s = np.vstack((df_train[\"x\"],df_train[\"y\"])).T\n",
    "\n",
    "num_basis = [2**2,5**2,9**2]\n",
    "knots_1d = [np.linspace(0,1,int(np.sqrt(i))) for i in num_basis]\n",
    "##Wendland kernel\n",
    "K = 0\n",
    "phi = np.zeros((N, sum(num_basis)))\n",
    "\n",
    "for res in range(len(num_basis)):\n",
    "    theta = 1/np.sqrt(num_basis[res])*2.5\n",
    "    knots_s1, knots_s2 = np.meshgrid(knots_1d[res],knots_1d[res])\n",
    "    knots = np.column_stack((knots_s1.flatten(),knots_s2.flatten()))\n",
    "    for i in range(num_basis[res]):\n",
    "        d = np.linalg.norm(s-knots[i,:],axis=1)/theta\n",
    "        for j in range(len(d)):\n",
    "            if d[j] >= 0 and d[j] <= 1:\n",
    "                phi[j,i + K] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "            else:\n",
    "                phi[j,i + K] = 0\n",
    "    K = K + num_basis[res]\n",
    "\n",
    "# DeepKriging model for continuous data\n",
    "model = Sequential()\n",
    "# model.add(Dense(100, input_dim = 2,  kernel_initializer='he_uniform', activation='relu'))\n",
    "model.add(Dense(100, input_dim = phi.shape[1],  \n",
    "                kernel_initializer='he_uniform', activation='relu'))\n",
    "# model.add(Dropout(rate=0.5))\n",
    "# model.add(BatchNormalization())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "#     model.add(Dense(100, activation='relu'))\n",
    "# model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "#     model.add(Dense(50, activation='relu'))\n",
    "#     model.add(Dense(50, activation='relu'))\n",
    "#     model.add(Dense(10, activation='relu'))\n",
    "#model.add(Dense(50, activation='relu'))\n",
    "#model.add(Dropout(rate=0.5))\n",
    "#     model.add(Dense(10, activation='relu'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(2, activation='linear'))\n",
    "#     quantile = 0.5\n",
    "optimizer = keras.optimizers.Adam(lr=0.001)\n",
    "model.compile(loss='mse', optimizer=optimizer)\n",
    "#     model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "callbacks = [EarlyStopping(monitor='val_loss', patience=200),\n",
    "             ModelCheckpoint(filepath='mean_model.h5', monitor='val_loss', save_best_only=True)]\n",
    "print(\"running model for mean. \")\n",
    "result = model.fit(phi, y, callbacks=callbacks,\n",
    "                   validation_data = (phi_test,y_test), epochs = 500, batch_size = 128, verbose = 0)\n",
    "\n",
    "model_mean = model #keras.models.load_model('mean_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6a5df48a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning:\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning:\n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "pred = model_mean.predict(phi_test)\n",
    "df_test[\"var1_mean\"] = pred[:,0]\n",
    "df_test[\"var2_mean\"] = pred[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "996144bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /Users/nagp/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:11: SettingWithCopyWarning:\n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "a = np.array([-2.47176554,-1.82406163,-1.08755835,-0.60572381,0.03170641,0.26759939,0.24032180])\n",
    "b = np.array([0.6715845,0.7423779,0.8441032,0.8847470,0.9492417,0.9276952,0.7906538])\n",
    "\n",
    "df_test.reset_index()\n",
    "for i in range(len(df_test)):\n",
    "    vec_distance = abs(df_test.iloc[i][\"var2_mean\"] - b*df_test.iloc[i][\"var1_mean\"] - a)/np.sqrt(1+b**2)\n",
    "    index = np.where(vec_distance == min(vec_distance))\n",
    "    \n",
    "#     print(index[0])\n",
    "#     print(df_test.iloc[i]['threshold'])\n",
    "    df_test.iloc[i]['threshold'] = index[0] + 1\n",
    "#     print(df_test.iloc[i]['threshold'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5252c6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6, 7])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(df_test[\"threshold\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91563a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for h in range(7):\n",
    "    df_test1 = df_test.loc[df_test['threshold'] == h+1]\n",
    "    #     print(df_test1.head())\n",
    "    N = len(df_test1)\n",
    "    s = np.vstack((df_test1[\"x\"],df_test1[\"y\"])).T\n",
    "\n",
    "    num_basis = [2**2,5**2,9**2]\n",
    "    knots_1d = [np.linspace(0,1,int(np.sqrt(i))) for i in num_basis]\n",
    "    ##Wendland kernel\n",
    "    K = 0\n",
    "    phi = np.zeros((N, sum(num_basis)))\n",
    "\n",
    "    for res in range(len(num_basis)):\n",
    "        theta = 1/np.sqrt(num_basis[res])*2.5\n",
    "        knots_s1, knots_s2 = np.meshgrid(knots_1d[res],knots_1d[res])\n",
    "        knots = np.column_stack((knots_s1.flatten(),knots_s2.flatten()))\n",
    "        for i in range(num_basis[res]):\n",
    "            d = np.linalg.norm(s-knots[i,:],axis=1)/theta\n",
    "            for j in range(len(d)):\n",
    "                if d[j] >= 0 and d[j] <= 1:\n",
    "                    phi[j,i + K] = (1-d[j])**6 * (35 * d[j]**2 + 18 * d[j] + 3)/3\n",
    "                else:\n",
    "                    phi[j,i + K] = 0\n",
    "        K = K + num_basis[res]\n",
    "    print(h)\n",
    "    model = model_list[h]\n",
    "    pred = model.predict(phi)\n",
    "    df_test1 = df_test1.reset_index(drop=True)\n",
    "    pred_df = pd.DataFrame(pred)\n",
    "    pred_df = pred_df.reset_index(drop=True)\n",
    "    df_test1 = pd.concat([df_test1,pred_df], axis = 1)\n",
    "    if(h == 0):\n",
    "        new_df_test = df_test1 \n",
    "    else:\n",
    "        print(h)\n",
    "        new_df_test = pd.concat([new_df_test,df_test1], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3db5365d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>var1</th>\n",
       "      <th>var2</th>\n",
       "      <th>proj_var1</th>\n",
       "      <th>proj_var2</th>\n",
       "      <th>threshold</th>\n",
       "      <th>dist_frm_orig</th>\n",
       "      <th>threshold2</th>\n",
       "      <th>threshold_var1</th>\n",
       "      <th>...</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022472</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>-2.460593</td>\n",
       "      <td>-4.079591</td>\n",
       "      <td>-2.439918</td>\n",
       "      <td>-4.110376</td>\n",
       "      <td>1</td>\n",
       "      <td>8.638244</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>1.744112e-27</td>\n",
       "      <td>2.734075e-18</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.900360e-37</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044944</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>-3.056903</td>\n",
       "      <td>-4.681487</td>\n",
       "      <td>-3.129453</td>\n",
       "      <td>-4.573458</td>\n",
       "      <td>1</td>\n",
       "      <td>14.210588</td>\n",
       "      <td>3</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>3.184049e-17</td>\n",
       "      <td>5.206039e-16</td>\n",
       "      <td>5.226224e-28</td>\n",
       "      <td>9.211120e-36</td>\n",
       "      <td>7.902752e-33</td>\n",
       "      <td>3.198152e-36</td>\n",
       "      <td>9.362142e-35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>-3.806602</td>\n",
       "      <td>-5.418866</td>\n",
       "      <td>-3.987406</td>\n",
       "      <td>-5.149646</td>\n",
       "      <td>1</td>\n",
       "      <td>23.070451</td>\n",
       "      <td>5</td>\n",
       "      <td>24</td>\n",
       "      <td>...</td>\n",
       "      <td>8.155365e-15</td>\n",
       "      <td>2.045845e-17</td>\n",
       "      <td>3.019527e-26</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.015293e-35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.725469e-37</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.932584</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>-3.029205</td>\n",
       "      <td>-4.408601</td>\n",
       "      <td>-2.984064</td>\n",
       "      <td>-4.475817</td>\n",
       "      <td>1</td>\n",
       "      <td>12.920859</td>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>...</td>\n",
       "      <td>6.194667e-25</td>\n",
       "      <td>3.153977e-15</td>\n",
       "      <td>1.588724e-36</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.462253e-35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.775941e-37</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.943820</td>\n",
       "      <td>0.044944</td>\n",
       "      <td>-3.257951</td>\n",
       "      <td>-5.119515</td>\n",
       "      <td>-3.470744</td>\n",
       "      <td>-4.802663</td>\n",
       "      <td>1</td>\n",
       "      <td>17.479150</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>5.786769e-25</td>\n",
       "      <td>4.078878e-21</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.067416</td>\n",
       "      <td>0.460674</td>\n",
       "      <td>-5.744804</td>\n",
       "      <td>-4.230377</td>\n",
       "      <td>-5.710041</td>\n",
       "      <td>-4.274344</td>\n",
       "      <td>7</td>\n",
       "      <td>52.986778</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>8.023334e-01</td>\n",
       "      <td>5.853111e-02</td>\n",
       "      <td>1.053958e-07</td>\n",
       "      <td>3.221059e-07</td>\n",
       "      <td>4.484468e-17</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.747080e-16</td>\n",
       "      <td>7.394674e-34</td>\n",
       "      <td>2.014575e-30</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.584270</td>\n",
       "      <td>0.438202</td>\n",
       "      <td>-2.397881</td>\n",
       "      <td>-1.739886</td>\n",
       "      <td>-2.438901</td>\n",
       "      <td>-1.688005</td>\n",
       "      <td>7</td>\n",
       "      <td>9.666680</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td>2.947227e-20</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.583898e-22</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.976700e-21</td>\n",
       "      <td>5.121621e-32</td>\n",
       "      <td>1.669491e-08</td>\n",
       "      <td>9.433476e-06</td>\n",
       "      <td>8.063034e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.370787</td>\n",
       "      <td>0.438202</td>\n",
       "      <td>-3.288142</td>\n",
       "      <td>-2.057056</td>\n",
       "      <td>-3.141018</td>\n",
       "      <td>-2.243136</td>\n",
       "      <td>7</td>\n",
       "      <td>16.033554</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "      <td>...</td>\n",
       "      <td>1.262687e-15</td>\n",
       "      <td>3.577124e-38</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>2.956096e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.661714e-38</td>\n",
       "      <td>4.081562e-21</td>\n",
       "      <td>7.661450e-16</td>\n",
       "      <td>9.460067e-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.393258</td>\n",
       "      <td>0.370787</td>\n",
       "      <td>-2.794351</td>\n",
       "      <td>-1.605171</td>\n",
       "      <td>-2.617321</td>\n",
       "      <td>-1.829073</td>\n",
       "      <td>7</td>\n",
       "      <td>11.132766</td>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>...</td>\n",
       "      <td>9.490100e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>7.221601e-28</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.679113e-32</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.853921e-14</td>\n",
       "      <td>4.207175e-09</td>\n",
       "      <td>3.960791e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.539326</td>\n",
       "      <td>0.584270</td>\n",
       "      <td>-4.984808</td>\n",
       "      <td>-3.397875</td>\n",
       "      <td>-4.837364</td>\n",
       "      <td>-3.584359</td>\n",
       "      <td>7</td>\n",
       "      <td>38.028272</td>\n",
       "      <td>8</td>\n",
       "      <td>18</td>\n",
       "      <td>...</td>\n",
       "      <td>4.151988e-16</td>\n",
       "      <td>1.474376e-27</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>4.107289e-35</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.932595e-37</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>810 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x         y      var1      var2  proj_var1  proj_var2  threshold  \\\n",
       "0    0.022472  0.719101 -2.460593 -4.079591  -2.439918  -4.110376          1   \n",
       "1    0.044944  0.797753 -3.056903 -4.681487  -3.129453  -4.573458          1   \n",
       "2    0.000000  0.842697 -3.806602 -5.418866  -3.987406  -5.149646          1   \n",
       "3    0.932584  0.707865 -3.029205 -4.408601  -2.984064  -4.475817          1   \n",
       "4    0.943820  0.044944 -3.257951 -5.119515  -3.470744  -4.802663          1   \n",
       "..        ...       ...       ...       ...        ...        ...        ...   \n",
       "135  0.067416  0.460674 -5.744804 -4.230377  -5.710041  -4.274344          7   \n",
       "136  0.584270  0.438202 -2.397881 -1.739886  -2.438901  -1.688005          7   \n",
       "137  0.370787  0.438202 -3.288142 -2.057056  -3.141018  -2.243136          7   \n",
       "138  0.393258  0.370787 -2.794351 -1.605171  -2.617321  -1.829073          7   \n",
       "139  0.539326  0.584270 -4.984808 -3.397875  -4.837364  -3.584359          7   \n",
       "\n",
       "     dist_frm_orig  threshold2  threshold_var1  ...            10  \\\n",
       "0         8.638244           2              32  ...  1.744112e-27   \n",
       "1        14.210588           3              28  ...  3.184049e-17   \n",
       "2        23.070451           5              24  ...  8.155365e-15   \n",
       "3        12.920859           3              29  ...  6.194667e-25   \n",
       "4        17.479150           4              27  ...  5.786769e-25   \n",
       "..             ...         ...             ...  ...           ...   \n",
       "135      52.986778          12              13  ...  8.023334e-01   \n",
       "136       9.666680           2              32  ...  2.947227e-20   \n",
       "137      16.033554           3              27  ...  1.262687e-15   \n",
       "138      11.132766           2              30  ...  9.490100e-24   \n",
       "139      38.028272           8              18  ...  4.151988e-16   \n",
       "\n",
       "               11            12            13            14            15  \\\n",
       "0    2.734075e-18  0.000000e+00  0.000000e+00  5.900360e-37  0.000000e+00   \n",
       "1    5.206039e-16  5.226224e-28  9.211120e-36  7.902752e-33  3.198152e-36   \n",
       "2    2.045845e-17  3.019527e-26  0.000000e+00  2.015293e-35  0.000000e+00   \n",
       "3    3.153977e-15  1.588724e-36  0.000000e+00  3.462253e-35  0.000000e+00   \n",
       "4    4.078878e-21  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
       "..            ...           ...           ...           ...           ...   \n",
       "135  5.853111e-02  1.053958e-07  3.221059e-07  4.484468e-17  0.000000e+00   \n",
       "136  0.000000e+00  0.000000e+00  3.583898e-22  0.000000e+00  4.976700e-21   \n",
       "137  3.577124e-38  0.000000e+00  2.956096e-24  0.000000e+00  0.000000e+00   \n",
       "138  0.000000e+00  0.000000e+00  7.221601e-28  0.000000e+00  1.679113e-32   \n",
       "139  1.474376e-27  0.000000e+00  4.107289e-35  0.000000e+00  0.000000e+00   \n",
       "\n",
       "               16            17            18            19  \n",
       "0    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "1    9.362142e-35  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "2    4.725469e-37  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "3    3.775941e-37  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "4    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  \n",
       "..            ...           ...           ...           ...  \n",
       "135  2.747080e-16  7.394674e-34  2.014575e-30  0.000000e+00  \n",
       "136  5.121621e-32  1.669491e-08  9.433476e-06  8.063034e-10  \n",
       "137  5.661714e-38  4.081562e-21  7.661450e-16  9.460067e-20  \n",
       "138  0.000000e+00  4.853921e-14  4.207175e-09  3.960791e-15  \n",
       "139  0.000000e+00  0.000000e+00  1.932595e-37  0.000000e+00  \n",
       "\n",
       "[810 rows x 33 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "17369f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_test.to_csv(\"median_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3efdb2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"train_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77b70eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
